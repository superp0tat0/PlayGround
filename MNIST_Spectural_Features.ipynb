{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST Spectural_Features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Tensorflow (GPU)",
      "language": "python",
      "name": "py3.6-tfgpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superp0tat0/PlayGround/blob/master/MNIST_Spectural_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHijRDhe8AQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff6a2db-df54-4749-8d5d-8c16a2b9dbe8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jan 30 22:49:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ1paqfWZAJA"
      },
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random                        # for generating random numbers\n",
        "\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.utils import np_utils                         # NumPy related tools\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import KernelPCA as KPCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import some additional tools\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "def model_status(model):\n",
        "    for layer in model.layers:\n",
        "      print(layer, layer.trainable)\n",
        "\n",
        "def build_model_single_dense(first_layer_neuron = 32):\n",
        "  model = Sequential()                                 # Linear stacking of layers\n",
        "  model.add(Dense(first_layer_neuron))                \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(10))                                 # final 10 FCN nodes\n",
        "  model.add(Activation('softmax'))                     # softmax activation\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def build_model_complex_dense():\n",
        "  model = Sequential()                                 # Linear stacking of layers\n",
        "  model.add(Dense(32))\n",
        "  model.add(BatchNormalization())             \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(64))\n",
        "  model.add(BatchNormalization())             \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(128))\n",
        "  model.add(BatchNormalization())             \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(64))\n",
        "  model.add(BatchNormalization())             \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(32))\n",
        "  model.add(BatchNormalization())             \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(10))                                 # final 10 FCN nodes\n",
        "  model.add(Activation('softmax'))                     # softmax activation\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vW96zcCvZAJN"
      },
      "source": [
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "#Flatten the X data for PCA features\n",
        "X_train_Flatten = X_train.reshape(60000, 28*28)\n",
        "X_test_Flatten = X_test.reshape(10000, 28*28)\n",
        "\n",
        "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "nb_classes = 10 # number of unique digits\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "y_random = np.array([random.randint(0,9) for i in range(60000)])\n",
        "Y_random = np_utils.to_categorical(y_random, nb_classes)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xp_JUp4eOoh"
      },
      "source": [
        "obj_pca = PCA(n_components=60)\n",
        "obj_pca.fit(X_train_Flatten)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "316h6rjXKElv",
        "outputId": "c55f72d9-2782-4f33-febd-a4d334a18510"
      },
      "source": [
        "pcs = obj_pca.components_.reshape(60,28,28)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeRnZ6lFLADu"
      },
      "source": [
        "# Empirical Study 1\n",
        "What does the Principal Components look like for the whole dataset?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmewAuEHJgTk"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (30,12) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(32):\n",
        "    plt.subplot(4,8,i+1)\n",
        "    plt.imshow(pcs[i], cmap='gray', interpolation='none')\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAqWZnnPwWIa"
      },
      "source": [
        "# Empirical Study 2a\n",
        "Will PCA benefit of convergence? Yes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zg-sjNwnXJy",
        "outputId": "5d25b510-3d12-4411-83bd-1f31a0946c47"
      },
      "source": [
        "# Treat the new PCs as the weights.\n",
        "new_X_train = X_train_Flatten @ obj_pca.components_.T\n",
        "new_X_test = X_test_Flatten @ obj_pca.components_.T\n",
        "print(new_X_train.shape)\n",
        "print(new_X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 60)\n",
            "(10000, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2wu6Ex0sn8dJ"
      },
      "source": [
        "pca_model = build_model_single_dense(32)\n",
        "pca_history = pca_model.fit(x=new_X_train, y=Y_train, epochs=50, steps_per_epoch=100, validation_data=(new_X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAjm6zmowsRu"
      },
      "source": [
        "naive_dense = build_model_single_dense(32)\n",
        "naive_history = naive_dense.fit(x=X_train_Flatten, y=Y_train, epochs=50, steps_per_epoch=100, validation_data=(X_test_Flatten, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "coga7IutqqpB",
        "outputId": "a68dd8b1-be81-4641-ea53-02b1c4acb613"
      },
      "source": [
        "%matplotlib inline\n",
        "plt.plot(pca_history.history['accuracy'])\n",
        "plt.plot(pca_history.history['val_accuracy'])\n",
        "plt.plot(naive_history.history['accuracy'])\n",
        "plt.plot(naive_history.history['val_accuracy'])\n",
        "plt.title('compare model')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['pca_accuracy', 'pca_val_accuracy', 'naive_dence_accuracy', 'naive_dense_val_accuracy'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4yCFngZ-NoY"
      },
      "source": [
        "# Empirical Study 2b\n",
        "What does the simple dense layer work with the random labeled datasets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOKHV2Al-W6T",
        "outputId": "3f74ee01-60b9-4668-a002-aaa85742ff41"
      },
      "source": [
        "random_dense = build_model_complex_dense()\n",
        "random_history = random_dense.fit(x = X_train_Flatten, y=Y_random, epochs=500, steps_per_epoch=100, validation_data=(X_test_Flatten, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 2s 14ms/step - loss: 2.4649 - accuracy: 0.0996 - val_loss: 2.3107 - val_accuracy: 0.1156\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.3020 - accuracy: 0.1189 - val_loss: 2.3390 - val_accuracy: 0.0862\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2879 - accuracy: 0.1291 - val_loss: 2.3172 - val_accuracy: 0.1035\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2808 - accuracy: 0.1361 - val_loss: 2.3007 - val_accuracy: 0.1156\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2724 - accuracy: 0.1439 - val_loss: 2.3041 - val_accuracy: 0.1249\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2640 - accuracy: 0.1533 - val_loss: 2.3255 - val_accuracy: 0.1033\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2594 - accuracy: 0.1553 - val_loss: 2.3691 - val_accuracy: 0.0989\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2471 - accuracy: 0.1620 - val_loss: 2.3424 - val_accuracy: 0.1022\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2397 - accuracy: 0.1690 - val_loss: 2.3804 - val_accuracy: 0.0932\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2305 - accuracy: 0.1726 - val_loss: 2.3427 - val_accuracy: 0.1072\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2183 - accuracy: 0.1856 - val_loss: 2.3538 - val_accuracy: 0.1197\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2062 - accuracy: 0.1887 - val_loss: 2.3418 - val_accuracy: 0.1146\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1980 - accuracy: 0.1933 - val_loss: 2.3609 - val_accuracy: 0.1170\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1877 - accuracy: 0.1980 - val_loss: 2.3827 - val_accuracy: 0.1054\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1744 - accuracy: 0.2044 - val_loss: 2.3669 - val_accuracy: 0.1187\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1666 - accuracy: 0.2120 - val_loss: 2.3959 - val_accuracy: 0.1062\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1550 - accuracy: 0.2178 - val_loss: 2.4127 - val_accuracy: 0.1050\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1487 - accuracy: 0.2191 - val_loss: 2.4075 - val_accuracy: 0.1139\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1385 - accuracy: 0.2253 - val_loss: 2.4421 - val_accuracy: 0.1041\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1222 - accuracy: 0.2315 - val_loss: 2.4499 - val_accuracy: 0.0981\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1138 - accuracy: 0.2385 - val_loss: 2.4751 - val_accuracy: 0.1066\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1045 - accuracy: 0.2409 - val_loss: 2.4817 - val_accuracy: 0.1090\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0975 - accuracy: 0.2440 - val_loss: 2.4782 - val_accuracy: 0.1085\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0834 - accuracy: 0.2502 - val_loss: 2.5080 - val_accuracy: 0.0974\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0801 - accuracy: 0.2509 - val_loss: 2.4964 - val_accuracy: 0.1061\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0632 - accuracy: 0.2602 - val_loss: 2.5158 - val_accuracy: 0.0980\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0581 - accuracy: 0.2629 - val_loss: 2.4966 - val_accuracy: 0.1072\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0453 - accuracy: 0.2708 - val_loss: 2.5231 - val_accuracy: 0.1070\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0401 - accuracy: 0.2703 - val_loss: 2.5429 - val_accuracy: 0.1035\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0297 - accuracy: 0.2750 - val_loss: 2.5351 - val_accuracy: 0.1040\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0263 - accuracy: 0.2783 - val_loss: 2.5874 - val_accuracy: 0.1009\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0138 - accuracy: 0.2827 - val_loss: 2.5543 - val_accuracy: 0.1068\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0080 - accuracy: 0.2857 - val_loss: 2.6068 - val_accuracy: 0.0976\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9985 - accuracy: 0.2860 - val_loss: 2.5689 - val_accuracy: 0.1070\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9844 - accuracy: 0.2940 - val_loss: 2.5689 - val_accuracy: 0.1115\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9808 - accuracy: 0.2940 - val_loss: 2.6138 - val_accuracy: 0.1066\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9740 - accuracy: 0.2954 - val_loss: 2.5857 - val_accuracy: 0.1078\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9713 - accuracy: 0.2960 - val_loss: 2.6244 - val_accuracy: 0.1049\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9572 - accuracy: 0.3036 - val_loss: 2.6130 - val_accuracy: 0.1093\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9546 - accuracy: 0.3052 - val_loss: 2.6183 - val_accuracy: 0.1037\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9493 - accuracy: 0.3042 - val_loss: 2.6766 - val_accuracy: 0.1001\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9390 - accuracy: 0.3113 - val_loss: 2.6584 - val_accuracy: 0.1040\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9425 - accuracy: 0.3114 - val_loss: 2.6920 - val_accuracy: 0.0996\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9334 - accuracy: 0.3145 - val_loss: 2.6727 - val_accuracy: 0.1066\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9240 - accuracy: 0.3173 - val_loss: 2.6366 - val_accuracy: 0.1116\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9270 - accuracy: 0.3154 - val_loss: 2.6355 - val_accuracy: 0.1153\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9141 - accuracy: 0.3242 - val_loss: 2.6862 - val_accuracy: 0.1059\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9144 - accuracy: 0.3223 - val_loss: 2.7136 - val_accuracy: 0.1016\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9052 - accuracy: 0.3232 - val_loss: 2.7035 - val_accuracy: 0.1017\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.8970 - accuracy: 0.3275 - val_loss: 2.7330 - val_accuracy: 0.1037\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8960 - accuracy: 0.3260 - val_loss: 2.7605 - val_accuracy: 0.1001\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8968 - accuracy: 0.3263 - val_loss: 2.7335 - val_accuracy: 0.1027\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8906 - accuracy: 0.3290 - val_loss: 2.7093 - val_accuracy: 0.1057\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8779 - accuracy: 0.3328 - val_loss: 2.6752 - val_accuracy: 0.1158\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8847 - accuracy: 0.3335 - val_loss: 2.7855 - val_accuracy: 0.0926\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8750 - accuracy: 0.3374 - val_loss: 2.7744 - val_accuracy: 0.0953\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8675 - accuracy: 0.3404 - val_loss: 2.7861 - val_accuracy: 0.1003\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8663 - accuracy: 0.3406 - val_loss: 2.7592 - val_accuracy: 0.1024\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8630 - accuracy: 0.3409 - val_loss: 2.7772 - val_accuracy: 0.0988\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8588 - accuracy: 0.3445 - val_loss: 2.7859 - val_accuracy: 0.1050\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8527 - accuracy: 0.3430 - val_loss: 2.8009 - val_accuracy: 0.0998\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8485 - accuracy: 0.3451 - val_loss: 2.7758 - val_accuracy: 0.1100\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8449 - accuracy: 0.3463 - val_loss: 2.7976 - val_accuracy: 0.1041\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8527 - accuracy: 0.3424 - val_loss: 2.8486 - val_accuracy: 0.0983\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8374 - accuracy: 0.3514 - val_loss: 2.8248 - val_accuracy: 0.0997\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8327 - accuracy: 0.3517 - val_loss: 2.8260 - val_accuracy: 0.0997\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8328 - accuracy: 0.3515 - val_loss: 2.8180 - val_accuracy: 0.1041\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8307 - accuracy: 0.3524 - val_loss: 2.8487 - val_accuracy: 0.0997\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8247 - accuracy: 0.3530 - val_loss: 2.8266 - val_accuracy: 0.1051\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8197 - accuracy: 0.3582 - val_loss: 2.7831 - val_accuracy: 0.1099\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8206 - accuracy: 0.3538 - val_loss: 2.8416 - val_accuracy: 0.1011\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8267 - accuracy: 0.3540 - val_loss: 2.8190 - val_accuracy: 0.1023\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8089 - accuracy: 0.3634 - val_loss: 2.8298 - val_accuracy: 0.1052\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8152 - accuracy: 0.3569 - val_loss: 2.8684 - val_accuracy: 0.1013\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.8110 - accuracy: 0.3576 - val_loss: 2.9140 - val_accuracy: 0.0972\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8063 - accuracy: 0.3600 - val_loss: 2.8471 - val_accuracy: 0.1105\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8035 - accuracy: 0.3637 - val_loss: 2.8279 - val_accuracy: 0.1087\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8030 - accuracy: 0.3632 - val_loss: 2.8922 - val_accuracy: 0.1035\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8013 - accuracy: 0.3634 - val_loss: 2.8796 - val_accuracy: 0.1050\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7945 - accuracy: 0.3679 - val_loss: 2.8526 - val_accuracy: 0.1116\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7894 - accuracy: 0.3697 - val_loss: 2.8499 - val_accuracy: 0.1091\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7903 - accuracy: 0.3688 - val_loss: 2.9149 - val_accuracy: 0.0971\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7879 - accuracy: 0.3700 - val_loss: 2.8762 - val_accuracy: 0.1068\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7844 - accuracy: 0.3710 - val_loss: 2.8840 - val_accuracy: 0.1054\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7770 - accuracy: 0.3729 - val_loss: 2.9078 - val_accuracy: 0.1056\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7785 - accuracy: 0.3711 - val_loss: 2.9074 - val_accuracy: 0.1020\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7744 - accuracy: 0.3737 - val_loss: 2.8873 - val_accuracy: 0.1077\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7706 - accuracy: 0.3749 - val_loss: 2.9517 - val_accuracy: 0.0942\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7759 - accuracy: 0.3698 - val_loss: 2.9029 - val_accuracy: 0.1041\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7599 - accuracy: 0.3788 - val_loss: 2.9242 - val_accuracy: 0.1063\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7774 - accuracy: 0.3713 - val_loss: 2.9296 - val_accuracy: 0.1010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7628 - accuracy: 0.3784 - val_loss: 2.9065 - val_accuracy: 0.1056\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7626 - accuracy: 0.3779 - val_loss: 2.9441 - val_accuracy: 0.1020\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7601 - accuracy: 0.3807 - val_loss: 2.9693 - val_accuracy: 0.1003\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7625 - accuracy: 0.3793 - val_loss: 2.9433 - val_accuracy: 0.1001\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7567 - accuracy: 0.3791 - val_loss: 2.9384 - val_accuracy: 0.1080\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7534 - accuracy: 0.3797 - val_loss: 2.9399 - val_accuracy: 0.1048\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7487 - accuracy: 0.3803 - val_loss: 2.9572 - val_accuracy: 0.1044\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7445 - accuracy: 0.3868 - val_loss: 2.9865 - val_accuracy: 0.0981\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.7491 - accuracy: 0.3822 - val_loss: 2.9677 - val_accuracy: 0.0965\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7480 - accuracy: 0.3852 - val_loss: 2.9947 - val_accuracy: 0.0941\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7384 - accuracy: 0.3870 - val_loss: 2.9570 - val_accuracy: 0.1100\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7394 - accuracy: 0.3904 - val_loss: 2.9766 - val_accuracy: 0.1032\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7444 - accuracy: 0.3842 - val_loss: 3.0065 - val_accuracy: 0.0975\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7416 - accuracy: 0.3884 - val_loss: 2.9955 - val_accuracy: 0.1018\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7383 - accuracy: 0.3860 - val_loss: 2.9977 - val_accuracy: 0.1012\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7297 - accuracy: 0.3898 - val_loss: 2.9536 - val_accuracy: 0.1072\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7234 - accuracy: 0.3954 - val_loss: 2.9965 - val_accuracy: 0.0956\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7291 - accuracy: 0.3891 - val_loss: 3.0078 - val_accuracy: 0.0970\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7277 - accuracy: 0.3886 - val_loss: 3.0124 - val_accuracy: 0.1001\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7259 - accuracy: 0.3942 - val_loss: 3.0191 - val_accuracy: 0.1014\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7316 - accuracy: 0.3875 - val_loss: 3.0223 - val_accuracy: 0.0973\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7250 - accuracy: 0.3916 - val_loss: 2.9796 - val_accuracy: 0.1082\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7139 - accuracy: 0.3959 - val_loss: 2.9843 - val_accuracy: 0.1053\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7174 - accuracy: 0.3960 - val_loss: 3.0336 - val_accuracy: 0.0977\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7141 - accuracy: 0.3978 - val_loss: 3.0584 - val_accuracy: 0.0949\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7195 - accuracy: 0.3931 - val_loss: 3.0565 - val_accuracy: 0.1006\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7156 - accuracy: 0.3956 - val_loss: 3.0321 - val_accuracy: 0.1014\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7188 - accuracy: 0.3934 - val_loss: 2.9927 - val_accuracy: 0.1093\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7085 - accuracy: 0.3994 - val_loss: 3.0584 - val_accuracy: 0.1013\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7164 - accuracy: 0.3936 - val_loss: 2.9906 - val_accuracy: 0.1074\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7014 - accuracy: 0.4010 - val_loss: 3.0472 - val_accuracy: 0.0985\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7097 - accuracy: 0.3982 - val_loss: 3.0804 - val_accuracy: 0.0999\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7105 - accuracy: 0.3974 - val_loss: 2.9772 - val_accuracy: 0.1122\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7032 - accuracy: 0.4012 - val_loss: 3.0383 - val_accuracy: 0.1032\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7012 - accuracy: 0.4038 - val_loss: 3.0748 - val_accuracy: 0.0980\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7040 - accuracy: 0.3999 - val_loss: 2.9967 - val_accuracy: 0.1123\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6962 - accuracy: 0.4016 - val_loss: 3.0348 - val_accuracy: 0.1047\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7046 - accuracy: 0.4005 - val_loss: 3.0082 - val_accuracy: 0.1053\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6936 - accuracy: 0.4010 - val_loss: 3.0705 - val_accuracy: 0.1001\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6940 - accuracy: 0.4054 - val_loss: 3.0833 - val_accuracy: 0.1046\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6966 - accuracy: 0.4041 - val_loss: 3.0846 - val_accuracy: 0.1014\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6973 - accuracy: 0.4037 - val_loss: 3.0808 - val_accuracy: 0.1061\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6955 - accuracy: 0.4028 - val_loss: 3.1050 - val_accuracy: 0.1039\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6868 - accuracy: 0.4049 - val_loss: 3.0730 - val_accuracy: 0.0976\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6946 - accuracy: 0.4025 - val_loss: 3.0636 - val_accuracy: 0.1055\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6896 - accuracy: 0.4071 - val_loss: 3.0369 - val_accuracy: 0.1049\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6852 - accuracy: 0.4066 - val_loss: 3.0718 - val_accuracy: 0.1027\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6905 - accuracy: 0.4056 - val_loss: 3.0766 - val_accuracy: 0.1054\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6847 - accuracy: 0.4045 - val_loss: 3.0762 - val_accuracy: 0.0981\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6886 - accuracy: 0.4048 - val_loss: 3.1032 - val_accuracy: 0.1023\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6840 - accuracy: 0.4063 - val_loss: 3.1109 - val_accuracy: 0.0989\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6852 - accuracy: 0.4037 - val_loss: 3.0476 - val_accuracy: 0.1072\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6834 - accuracy: 0.4072 - val_loss: 3.1174 - val_accuracy: 0.0983\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6716 - accuracy: 0.4081 - val_loss: 3.0852 - val_accuracy: 0.1023\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6809 - accuracy: 0.4070 - val_loss: 3.1163 - val_accuracy: 0.1019\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6710 - accuracy: 0.4133 - val_loss: 3.1442 - val_accuracy: 0.0992\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6748 - accuracy: 0.4114 - val_loss: 3.0949 - val_accuracy: 0.1071\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6708 - accuracy: 0.4112 - val_loss: 3.0875 - val_accuracy: 0.1128\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6748 - accuracy: 0.4086 - val_loss: 3.1127 - val_accuracy: 0.1009\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6829 - accuracy: 0.4081 - val_loss: 3.0811 - val_accuracy: 0.1082\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6735 - accuracy: 0.4146 - val_loss: 3.0865 - val_accuracy: 0.1022\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6783 - accuracy: 0.4077 - val_loss: 3.0981 - val_accuracy: 0.1014\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6621 - accuracy: 0.4145 - val_loss: 3.1085 - val_accuracy: 0.1079\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6713 - accuracy: 0.4122 - val_loss: 3.0576 - val_accuracy: 0.1077\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6677 - accuracy: 0.4125 - val_loss: 3.1125 - val_accuracy: 0.1054\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6639 - accuracy: 0.4165 - val_loss: 3.1144 - val_accuracy: 0.0971\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6658 - accuracy: 0.4171 - val_loss: 3.1281 - val_accuracy: 0.0997\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6649 - accuracy: 0.4157 - val_loss: 3.1046 - val_accuracy: 0.1127\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6595 - accuracy: 0.4191 - val_loss: 3.1019 - val_accuracy: 0.1073\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6519 - accuracy: 0.4165 - val_loss: 3.0835 - val_accuracy: 0.1092\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6589 - accuracy: 0.4154 - val_loss: 3.1436 - val_accuracy: 0.1028\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6652 - accuracy: 0.4132 - val_loss: 3.1287 - val_accuracy: 0.1083\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6560 - accuracy: 0.4151 - val_loss: 3.0730 - val_accuracy: 0.1099\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6664 - accuracy: 0.4129 - val_loss: 3.1706 - val_accuracy: 0.1022\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6624 - accuracy: 0.4153 - val_loss: 3.0827 - val_accuracy: 0.1081\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6514 - accuracy: 0.4187 - val_loss: 3.1310 - val_accuracy: 0.1020\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6515 - accuracy: 0.4213 - val_loss: 3.1816 - val_accuracy: 0.1018\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6524 - accuracy: 0.4209 - val_loss: 3.1464 - val_accuracy: 0.1000\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6549 - accuracy: 0.4179 - val_loss: 3.1353 - val_accuracy: 0.1068\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6562 - accuracy: 0.4192 - val_loss: 3.1758 - val_accuracy: 0.1018\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6407 - accuracy: 0.4249 - val_loss: 3.1596 - val_accuracy: 0.1074\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6507 - accuracy: 0.4181 - val_loss: 3.1213 - val_accuracy: 0.1156\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6509 - accuracy: 0.4193 - val_loss: 3.1357 - val_accuracy: 0.1068\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6490 - accuracy: 0.4199 - val_loss: 3.1602 - val_accuracy: 0.1025\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6477 - accuracy: 0.4200 - val_loss: 3.1571 - val_accuracy: 0.1019\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6476 - accuracy: 0.4227 - val_loss: 3.1867 - val_accuracy: 0.0996\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6545 - accuracy: 0.4201 - val_loss: 3.1723 - val_accuracy: 0.1019\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6435 - accuracy: 0.4203 - val_loss: 3.1561 - val_accuracy: 0.1027\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6479 - accuracy: 0.4197 - val_loss: 3.1678 - val_accuracy: 0.1033\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6417 - accuracy: 0.4239 - val_loss: 3.1967 - val_accuracy: 0.1009\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6434 - accuracy: 0.4183 - val_loss: 3.1717 - val_accuracy: 0.1012\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6301 - accuracy: 0.4251 - val_loss: 3.1595 - val_accuracy: 0.1101\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6467 - accuracy: 0.4220 - val_loss: 3.1965 - val_accuracy: 0.1021\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6328 - accuracy: 0.4243 - val_loss: 3.1797 - val_accuracy: 0.1033\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6369 - accuracy: 0.4241 - val_loss: 3.2066 - val_accuracy: 0.0966\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6341 - accuracy: 0.4225 - val_loss: 3.1674 - val_accuracy: 0.1047\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6317 - accuracy: 0.4233 - val_loss: 3.1699 - val_accuracy: 0.1021\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6378 - accuracy: 0.4210 - val_loss: 3.1958 - val_accuracy: 0.0995\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6346 - accuracy: 0.4241 - val_loss: 3.1540 - val_accuracy: 0.1052\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6413 - accuracy: 0.4220 - val_loss: 3.1913 - val_accuracy: 0.1042\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6332 - accuracy: 0.4254 - val_loss: 3.1907 - val_accuracy: 0.1024\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6312 - accuracy: 0.4273 - val_loss: 3.1834 - val_accuracy: 0.1077\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6328 - accuracy: 0.4240 - val_loss: 3.1977 - val_accuracy: 0.1081\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6316 - accuracy: 0.4259 - val_loss: 3.1880 - val_accuracy: 0.1088\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6275 - accuracy: 0.4265 - val_loss: 3.1804 - val_accuracy: 0.1058\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6259 - accuracy: 0.4296 - val_loss: 3.2316 - val_accuracy: 0.1017\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6207 - accuracy: 0.4330 - val_loss: 3.2203 - val_accuracy: 0.1003\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6296 - accuracy: 0.4251 - val_loss: 3.1969 - val_accuracy: 0.1049\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6245 - accuracy: 0.4298 - val_loss: 3.2074 - val_accuracy: 0.1055\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6291 - accuracy: 0.4243 - val_loss: 3.2145 - val_accuracy: 0.1019\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6313 - accuracy: 0.4262 - val_loss: 3.2218 - val_accuracy: 0.0981\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6251 - accuracy: 0.4275 - val_loss: 3.1867 - val_accuracy: 0.1071\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6195 - accuracy: 0.4273 - val_loss: 3.2172 - val_accuracy: 0.1013\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6203 - accuracy: 0.4299 - val_loss: 3.1818 - val_accuracy: 0.1034\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6216 - accuracy: 0.4288 - val_loss: 3.2140 - val_accuracy: 0.1057\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6243 - accuracy: 0.4282 - val_loss: 3.2032 - val_accuracy: 0.1055\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6167 - accuracy: 0.4312 - val_loss: 3.2474 - val_accuracy: 0.0962\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6306 - accuracy: 0.4270 - val_loss: 3.2491 - val_accuracy: 0.0971\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6194 - accuracy: 0.4307 - val_loss: 3.2033 - val_accuracy: 0.1056\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6223 - accuracy: 0.4260 - val_loss: 3.1847 - val_accuracy: 0.1166\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6305 - accuracy: 0.4291 - val_loss: 3.2225 - val_accuracy: 0.1067\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6221 - accuracy: 0.4316 - val_loss: 3.1992 - val_accuracy: 0.0991\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6240 - accuracy: 0.4306 - val_loss: 3.1800 - val_accuracy: 0.1050\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6169 - accuracy: 0.4316 - val_loss: 3.1925 - val_accuracy: 0.1113\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6118 - accuracy: 0.4340 - val_loss: 3.2590 - val_accuracy: 0.0979\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6182 - accuracy: 0.4307 - val_loss: 3.2317 - val_accuracy: 0.1037\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6102 - accuracy: 0.4328 - val_loss: 3.2246 - val_accuracy: 0.1065\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6201 - accuracy: 0.4283 - val_loss: 3.1972 - val_accuracy: 0.1049\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6081 - accuracy: 0.4338 - val_loss: 3.2612 - val_accuracy: 0.0995\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6136 - accuracy: 0.4325 - val_loss: 3.2564 - val_accuracy: 0.1010\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6135 - accuracy: 0.4317 - val_loss: 3.1941 - val_accuracy: 0.1121\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6116 - accuracy: 0.4348 - val_loss: 3.2258 - val_accuracy: 0.1040\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6075 - accuracy: 0.4326 - val_loss: 3.2188 - val_accuracy: 0.1037\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6071 - accuracy: 0.4337 - val_loss: 3.1805 - val_accuracy: 0.1104\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6088 - accuracy: 0.4334 - val_loss: 3.2251 - val_accuracy: 0.1067\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6119 - accuracy: 0.4341 - val_loss: 3.2479 - val_accuracy: 0.1022\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6086 - accuracy: 0.4366 - val_loss: 3.2554 - val_accuracy: 0.1052\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6061 - accuracy: 0.4324 - val_loss: 3.2397 - val_accuracy: 0.1096\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6052 - accuracy: 0.4354 - val_loss: 3.2508 - val_accuracy: 0.1004\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6041 - accuracy: 0.4340 - val_loss: 3.2596 - val_accuracy: 0.1040\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6020 - accuracy: 0.4363 - val_loss: 3.2717 - val_accuracy: 0.1011\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6078 - accuracy: 0.4307 - val_loss: 3.2313 - val_accuracy: 0.1039\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6027 - accuracy: 0.4380 - val_loss: 3.2527 - val_accuracy: 0.1069\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5962 - accuracy: 0.4398 - val_loss: 3.2179 - val_accuracy: 0.1082\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6086 - accuracy: 0.4344 - val_loss: 3.2595 - val_accuracy: 0.1069\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6011 - accuracy: 0.4388 - val_loss: 3.2189 - val_accuracy: 0.1143\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6070 - accuracy: 0.4343 - val_loss: 3.2808 - val_accuracy: 0.1054\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6122 - accuracy: 0.4355 - val_loss: 3.2404 - val_accuracy: 0.1125\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6084 - accuracy: 0.4353 - val_loss: 3.2656 - val_accuracy: 0.1063\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6016 - accuracy: 0.4343 - val_loss: 3.2301 - val_accuracy: 0.1115\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5942 - accuracy: 0.4393 - val_loss: 3.2824 - val_accuracy: 0.1068\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5913 - accuracy: 0.4416 - val_loss: 3.2841 - val_accuracy: 0.1000\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6012 - accuracy: 0.4379 - val_loss: 3.2631 - val_accuracy: 0.1036\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5966 - accuracy: 0.4388 - val_loss: 3.3035 - val_accuracy: 0.1067\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6002 - accuracy: 0.4355 - val_loss: 3.2828 - val_accuracy: 0.1090\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5819 - accuracy: 0.4447 - val_loss: 3.2806 - val_accuracy: 0.1034\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5928 - accuracy: 0.4397 - val_loss: 3.2805 - val_accuracy: 0.0995\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6038 - accuracy: 0.4351 - val_loss: 3.2987 - val_accuracy: 0.1029\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5913 - accuracy: 0.4453 - val_loss: 3.2491 - val_accuracy: 0.1057\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5887 - accuracy: 0.4426 - val_loss: 3.2437 - val_accuracy: 0.1091\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6010 - accuracy: 0.4408 - val_loss: 3.2460 - val_accuracy: 0.1056\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5912 - accuracy: 0.4379 - val_loss: 3.2687 - val_accuracy: 0.1094\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5951 - accuracy: 0.4349 - val_loss: 3.2829 - val_accuracy: 0.1128\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5896 - accuracy: 0.4395 - val_loss: 3.2537 - val_accuracy: 0.0993\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5943 - accuracy: 0.4375 - val_loss: 3.2633 - val_accuracy: 0.1026\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5982 - accuracy: 0.4370 - val_loss: 3.2577 - val_accuracy: 0.1079\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5936 - accuracy: 0.4399 - val_loss: 3.2658 - val_accuracy: 0.1108\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5884 - accuracy: 0.4429 - val_loss: 3.2745 - val_accuracy: 0.1049\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5813 - accuracy: 0.4442 - val_loss: 3.2693 - val_accuracy: 0.1105\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5914 - accuracy: 0.4408 - val_loss: 3.3171 - val_accuracy: 0.1092\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5883 - accuracy: 0.4408 - val_loss: 3.3124 - val_accuracy: 0.1035\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5872 - accuracy: 0.4423 - val_loss: 3.2438 - val_accuracy: 0.1105\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5801 - accuracy: 0.4441 - val_loss: 3.2858 - val_accuracy: 0.1071\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5809 - accuracy: 0.4453 - val_loss: 3.2932 - val_accuracy: 0.1048\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5914 - accuracy: 0.4410 - val_loss: 3.3235 - val_accuracy: 0.1025\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5874 - accuracy: 0.4407 - val_loss: 3.2941 - val_accuracy: 0.1101\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5801 - accuracy: 0.4448 - val_loss: 3.3350 - val_accuracy: 0.1020\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5877 - accuracy: 0.4413 - val_loss: 3.2948 - val_accuracy: 0.1036\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5825 - accuracy: 0.4439 - val_loss: 3.3212 - val_accuracy: 0.1033\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5829 - accuracy: 0.4435 - val_loss: 3.3128 - val_accuracy: 0.1043\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5828 - accuracy: 0.4426 - val_loss: 3.3021 - val_accuracy: 0.1049\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5776 - accuracy: 0.4455 - val_loss: 3.2976 - val_accuracy: 0.1098\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5764 - accuracy: 0.4452 - val_loss: 3.3400 - val_accuracy: 0.1018\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5716 - accuracy: 0.4491 - val_loss: 3.3443 - val_accuracy: 0.1013\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5799 - accuracy: 0.4429 - val_loss: 3.2944 - val_accuracy: 0.1065\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5876 - accuracy: 0.4391 - val_loss: 3.3623 - val_accuracy: 0.1038\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5818 - accuracy: 0.4417 - val_loss: 3.3292 - val_accuracy: 0.1077\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5820 - accuracy: 0.4457 - val_loss: 3.3018 - val_accuracy: 0.1077\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5829 - accuracy: 0.4417 - val_loss: 3.3084 - val_accuracy: 0.1024\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5812 - accuracy: 0.4467 - val_loss: 3.3110 - val_accuracy: 0.1108\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5774 - accuracy: 0.4468 - val_loss: 3.3788 - val_accuracy: 0.1007\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5821 - accuracy: 0.4436 - val_loss: 3.3526 - val_accuracy: 0.0974\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5839 - accuracy: 0.4422 - val_loss: 3.3129 - val_accuracy: 0.1066\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5720 - accuracy: 0.4482 - val_loss: 3.3432 - val_accuracy: 0.1063\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5702 - accuracy: 0.4472 - val_loss: 3.3288 - val_accuracy: 0.1032\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5719 - accuracy: 0.4468 - val_loss: 3.3414 - val_accuracy: 0.1023\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5765 - accuracy: 0.4456 - val_loss: 3.3061 - val_accuracy: 0.1090\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5731 - accuracy: 0.4482 - val_loss: 3.3251 - val_accuracy: 0.1010\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5778 - accuracy: 0.4421 - val_loss: 3.3457 - val_accuracy: 0.1016\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5770 - accuracy: 0.4438 - val_loss: 3.3265 - val_accuracy: 0.1028\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5739 - accuracy: 0.4435 - val_loss: 3.3241 - val_accuracy: 0.1029\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5813 - accuracy: 0.4436 - val_loss: 3.3276 - val_accuracy: 0.1077\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5718 - accuracy: 0.4452 - val_loss: 3.3624 - val_accuracy: 0.1015\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5726 - accuracy: 0.4515 - val_loss: 3.3489 - val_accuracy: 0.1041\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5695 - accuracy: 0.4477 - val_loss: 3.3288 - val_accuracy: 0.1071\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5737 - accuracy: 0.4449 - val_loss: 3.3574 - val_accuracy: 0.1048\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5729 - accuracy: 0.4487 - val_loss: 3.3730 - val_accuracy: 0.1012\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.5700 - accuracy: 0.4465 - val_loss: 3.3152 - val_accuracy: 0.1085\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5750 - accuracy: 0.4436 - val_loss: 3.3593 - val_accuracy: 0.1088\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5813 - accuracy: 0.4417 - val_loss: 3.3394 - val_accuracy: 0.1091\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5719 - accuracy: 0.4479 - val_loss: 3.3078 - val_accuracy: 0.1144\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5750 - accuracy: 0.4455 - val_loss: 3.3332 - val_accuracy: 0.1058\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5715 - accuracy: 0.4461 - val_loss: 3.3321 - val_accuracy: 0.1109\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5653 - accuracy: 0.4504 - val_loss: 3.3423 - val_accuracy: 0.1038\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5710 - accuracy: 0.4467 - val_loss: 3.3523 - val_accuracy: 0.1072\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5748 - accuracy: 0.4452 - val_loss: 3.3099 - val_accuracy: 0.1068\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5636 - accuracy: 0.4511 - val_loss: 3.3252 - val_accuracy: 0.1073\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5623 - accuracy: 0.4485 - val_loss: 3.3658 - val_accuracy: 0.1005\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5618 - accuracy: 0.4495 - val_loss: 3.3754 - val_accuracy: 0.1063\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5646 - accuracy: 0.4510 - val_loss: 3.3378 - val_accuracy: 0.1076\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5604 - accuracy: 0.4516 - val_loss: 3.3796 - val_accuracy: 0.1048\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5640 - accuracy: 0.4511 - val_loss: 3.3339 - val_accuracy: 0.1111\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5573 - accuracy: 0.4531 - val_loss: 3.3718 - val_accuracy: 0.1073\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5515 - accuracy: 0.4535 - val_loss: 3.3726 - val_accuracy: 0.1008\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5600 - accuracy: 0.4514 - val_loss: 3.3851 - val_accuracy: 0.1019\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5609 - accuracy: 0.4538 - val_loss: 3.3096 - val_accuracy: 0.1098\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5718 - accuracy: 0.4471 - val_loss: 3.3599 - val_accuracy: 0.1050\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5632 - accuracy: 0.4504 - val_loss: 3.3368 - val_accuracy: 0.1049\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5593 - accuracy: 0.4500 - val_loss: 3.3717 - val_accuracy: 0.1025\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5587 - accuracy: 0.4526 - val_loss: 3.3852 - val_accuracy: 0.0979\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5572 - accuracy: 0.4499 - val_loss: 3.4114 - val_accuracy: 0.0976\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5575 - accuracy: 0.4536 - val_loss: 3.3965 - val_accuracy: 0.0944\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5582 - accuracy: 0.4498 - val_loss: 3.3397 - val_accuracy: 0.1126\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5473 - accuracy: 0.4543 - val_loss: 3.3824 - val_accuracy: 0.1051\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5566 - accuracy: 0.4489 - val_loss: 3.4086 - val_accuracy: 0.1075\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5580 - accuracy: 0.4510 - val_loss: 3.3960 - val_accuracy: 0.1026\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5531 - accuracy: 0.4545 - val_loss: 3.3902 - val_accuracy: 0.1021\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5658 - accuracy: 0.4498 - val_loss: 3.3715 - val_accuracy: 0.1046\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5622 - accuracy: 0.4473 - val_loss: 3.3573 - val_accuracy: 0.1097\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5624 - accuracy: 0.4484 - val_loss: 3.4132 - val_accuracy: 0.1031\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5612 - accuracy: 0.4504 - val_loss: 3.3994 - val_accuracy: 0.1011\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5555 - accuracy: 0.4515 - val_loss: 3.3851 - val_accuracy: 0.1011\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5569 - accuracy: 0.4538 - val_loss: 3.3795 - val_accuracy: 0.1034\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5529 - accuracy: 0.4545 - val_loss: 3.4290 - val_accuracy: 0.1057\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5534 - accuracy: 0.4529 - val_loss: 3.3652 - val_accuracy: 0.1068\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5548 - accuracy: 0.4523 - val_loss: 3.4069 - val_accuracy: 0.0994\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5545 - accuracy: 0.4526 - val_loss: 3.4076 - val_accuracy: 0.1036\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5506 - accuracy: 0.4534 - val_loss: 3.3825 - val_accuracy: 0.1003\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5589 - accuracy: 0.4520 - val_loss: 3.3882 - val_accuracy: 0.1031\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5541 - accuracy: 0.4533 - val_loss: 3.4038 - val_accuracy: 0.1058\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5446 - accuracy: 0.4579 - val_loss: 3.4171 - val_accuracy: 0.1065\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5547 - accuracy: 0.4523 - val_loss: 3.4174 - val_accuracy: 0.1012\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5536 - accuracy: 0.4541 - val_loss: 3.3992 - val_accuracy: 0.0994\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5518 - accuracy: 0.4566 - val_loss: 3.3910 - val_accuracy: 0.1074\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5445 - accuracy: 0.4578 - val_loss: 3.3539 - val_accuracy: 0.1079\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5532 - accuracy: 0.4565 - val_loss: 3.3925 - val_accuracy: 0.1085\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5496 - accuracy: 0.4552 - val_loss: 3.4130 - val_accuracy: 0.1022\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5439 - accuracy: 0.4560 - val_loss: 3.3847 - val_accuracy: 0.1077\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.5474 - accuracy: 0.4556 - val_loss: 3.4054 - val_accuracy: 0.1065\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5470 - accuracy: 0.4552 - val_loss: 3.4088 - val_accuracy: 0.1058\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5505 - accuracy: 0.4559 - val_loss: 3.3999 - val_accuracy: 0.1063\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5578 - accuracy: 0.4522 - val_loss: 3.4188 - val_accuracy: 0.1003\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5458 - accuracy: 0.4521 - val_loss: 3.3893 - val_accuracy: 0.1034\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5440 - accuracy: 0.4583 - val_loss: 3.4105 - val_accuracy: 0.1095\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5446 - accuracy: 0.4546 - val_loss: 3.4165 - val_accuracy: 0.1030\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5455 - accuracy: 0.4550 - val_loss: 3.4247 - val_accuracy: 0.1018\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5396 - accuracy: 0.4574 - val_loss: 3.4209 - val_accuracy: 0.1071\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5496 - accuracy: 0.4549 - val_loss: 3.4433 - val_accuracy: 0.1043\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5464 - accuracy: 0.4540 - val_loss: 3.4410 - val_accuracy: 0.1062\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5408 - accuracy: 0.4583 - val_loss: 3.4101 - val_accuracy: 0.0985\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5456 - accuracy: 0.4548 - val_loss: 3.4183 - val_accuracy: 0.1029\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5568 - accuracy: 0.4515 - val_loss: 3.4329 - val_accuracy: 0.1014\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5582 - accuracy: 0.4515 - val_loss: 3.3881 - val_accuracy: 0.1092\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5407 - accuracy: 0.4586 - val_loss: 3.4401 - val_accuracy: 0.1048\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5327 - accuracy: 0.4617 - val_loss: 3.3848 - val_accuracy: 0.1069\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5416 - accuracy: 0.4551 - val_loss: 3.4132 - val_accuracy: 0.1033\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5489 - accuracy: 0.4543 - val_loss: 3.4605 - val_accuracy: 0.0989\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5521 - accuracy: 0.4504 - val_loss: 3.4138 - val_accuracy: 0.1086\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5433 - accuracy: 0.4531 - val_loss: 3.4602 - val_accuracy: 0.0950\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5429 - accuracy: 0.4552 - val_loss: 3.4024 - val_accuracy: 0.1054\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5419 - accuracy: 0.4529 - val_loss: 3.4443 - val_accuracy: 0.1000\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5448 - accuracy: 0.4548 - val_loss: 3.4159 - val_accuracy: 0.1053\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5379 - accuracy: 0.4568 - val_loss: 3.4298 - val_accuracy: 0.1069\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5320 - accuracy: 0.4584 - val_loss: 3.4475 - val_accuracy: 0.1005\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5309 - accuracy: 0.4622 - val_loss: 3.4209 - val_accuracy: 0.1020\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5332 - accuracy: 0.4597 - val_loss: 3.4311 - val_accuracy: 0.1038\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5398 - accuracy: 0.4583 - val_loss: 3.4346 - val_accuracy: 0.1058\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5409 - accuracy: 0.4562 - val_loss: 3.4421 - val_accuracy: 0.0993\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5381 - accuracy: 0.4599 - val_loss: 3.4386 - val_accuracy: 0.1046\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5457 - accuracy: 0.4540 - val_loss: 3.4697 - val_accuracy: 0.0983\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5378 - accuracy: 0.4596 - val_loss: 3.4364 - val_accuracy: 0.1037\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5418 - accuracy: 0.4589 - val_loss: 3.4188 - val_accuracy: 0.1049\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5384 - accuracy: 0.4584 - val_loss: 3.4584 - val_accuracy: 0.1027\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5402 - accuracy: 0.4572 - val_loss: 3.4810 - val_accuracy: 0.0974\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5468 - accuracy: 0.4550 - val_loss: 3.4286 - val_accuracy: 0.1070\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5421 - accuracy: 0.4571 - val_loss: 3.4588 - val_accuracy: 0.1038\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5415 - accuracy: 0.4577 - val_loss: 3.4426 - val_accuracy: 0.1059\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5368 - accuracy: 0.4575 - val_loss: 3.4629 - val_accuracy: 0.1013\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5385 - accuracy: 0.4588 - val_loss: 3.4421 - val_accuracy: 0.1024\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5364 - accuracy: 0.4610 - val_loss: 3.4720 - val_accuracy: 0.0999\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5396 - accuracy: 0.4577 - val_loss: 3.4393 - val_accuracy: 0.0983\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5431 - accuracy: 0.4560 - val_loss: 3.4551 - val_accuracy: 0.1027\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5267 - accuracy: 0.4624 - val_loss: 3.4556 - val_accuracy: 0.1061\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5285 - accuracy: 0.4619 - val_loss: 3.4603 - val_accuracy: 0.1078\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5290 - accuracy: 0.4618 - val_loss: 3.4474 - val_accuracy: 0.1016\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5375 - accuracy: 0.4581 - val_loss: 3.4425 - val_accuracy: 0.1007\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5331 - accuracy: 0.4603 - val_loss: 3.4594 - val_accuracy: 0.1007\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5384 - accuracy: 0.4577 - val_loss: 3.4519 - val_accuracy: 0.1026\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.5296 - accuracy: 0.4616 - val_loss: 3.4567 - val_accuracy: 0.1003\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5344 - accuracy: 0.4594 - val_loss: 3.4616 - val_accuracy: 0.1028\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5256 - accuracy: 0.4655 - val_loss: 3.4645 - val_accuracy: 0.1007\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5298 - accuracy: 0.4603 - val_loss: 3.4922 - val_accuracy: 0.0983\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5309 - accuracy: 0.4625 - val_loss: 3.4534 - val_accuracy: 0.1042\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5268 - accuracy: 0.4632 - val_loss: 3.4531 - val_accuracy: 0.0989\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5234 - accuracy: 0.4647 - val_loss: 3.4449 - val_accuracy: 0.1117\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5380 - accuracy: 0.4549 - val_loss: 3.4858 - val_accuracy: 0.0924\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5366 - accuracy: 0.4578 - val_loss: 3.4796 - val_accuracy: 0.1028\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5370 - accuracy: 0.4595 - val_loss: 3.4459 - val_accuracy: 0.1054\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5362 - accuracy: 0.4558 - val_loss: 3.4677 - val_accuracy: 0.1023\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5300 - accuracy: 0.4596 - val_loss: 3.4998 - val_accuracy: 0.1015\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5184 - accuracy: 0.4631 - val_loss: 3.4794 - val_accuracy: 0.1035\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5263 - accuracy: 0.4646 - val_loss: 3.4777 - val_accuracy: 0.1100\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5269 - accuracy: 0.4634 - val_loss: 3.4672 - val_accuracy: 0.1034\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5349 - accuracy: 0.4597 - val_loss: 3.4956 - val_accuracy: 0.0981\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5353 - accuracy: 0.4575 - val_loss: 3.4782 - val_accuracy: 0.0986\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5180 - accuracy: 0.4626 - val_loss: 3.4343 - val_accuracy: 0.1021\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5219 - accuracy: 0.4668 - val_loss: 3.4609 - val_accuracy: 0.0996\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5271 - accuracy: 0.4632 - val_loss: 3.4740 - val_accuracy: 0.1050\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5269 - accuracy: 0.4593 - val_loss: 3.4700 - val_accuracy: 0.1018\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5283 - accuracy: 0.4609 - val_loss: 3.4504 - val_accuracy: 0.1022\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5192 - accuracy: 0.4642 - val_loss: 3.4498 - val_accuracy: 0.1052\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5335 - accuracy: 0.4620 - val_loss: 3.4953 - val_accuracy: 0.0979\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5297 - accuracy: 0.4621 - val_loss: 3.4344 - val_accuracy: 0.1084\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5215 - accuracy: 0.4652 - val_loss: 3.4754 - val_accuracy: 0.1022\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5317 - accuracy: 0.4613 - val_loss: 3.4976 - val_accuracy: 0.0998\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5126 - accuracy: 0.4664 - val_loss: 3.4644 - val_accuracy: 0.0994\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5240 - accuracy: 0.4644 - val_loss: 3.5017 - val_accuracy: 0.0985\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5241 - accuracy: 0.4663 - val_loss: 3.4750 - val_accuracy: 0.1073\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5277 - accuracy: 0.4633 - val_loss: 3.5224 - val_accuracy: 0.0957\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5244 - accuracy: 0.4606 - val_loss: 3.4967 - val_accuracy: 0.1065\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5235 - accuracy: 0.4633 - val_loss: 3.4528 - val_accuracy: 0.1076\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5232 - accuracy: 0.4608 - val_loss: 3.4544 - val_accuracy: 0.1032\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5290 - accuracy: 0.4618 - val_loss: 3.5167 - val_accuracy: 0.0996\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5227 - accuracy: 0.4638 - val_loss: 3.4890 - val_accuracy: 0.1014\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5201 - accuracy: 0.4649 - val_loss: 3.5119 - val_accuracy: 0.0983\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5205 - accuracy: 0.4619 - val_loss: 3.4611 - val_accuracy: 0.1023\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5154 - accuracy: 0.4659 - val_loss: 3.4866 - val_accuracy: 0.1051\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5178 - accuracy: 0.4622 - val_loss: 3.4688 - val_accuracy: 0.1039\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5199 - accuracy: 0.4651 - val_loss: 3.4898 - val_accuracy: 0.1056\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5283 - accuracy: 0.4638 - val_loss: 3.4750 - val_accuracy: 0.1019\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5211 - accuracy: 0.4607 - val_loss: 3.4863 - val_accuracy: 0.1026\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5165 - accuracy: 0.4658 - val_loss: 3.4707 - val_accuracy: 0.1066\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5231 - accuracy: 0.4623 - val_loss: 3.4905 - val_accuracy: 0.0984\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5266 - accuracy: 0.4586 - val_loss: 3.4545 - val_accuracy: 0.1040\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5133 - accuracy: 0.4696 - val_loss: 3.5132 - val_accuracy: 0.0977\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5182 - accuracy: 0.4680 - val_loss: 3.5165 - val_accuracy: 0.1054\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5295 - accuracy: 0.4611 - val_loss: 3.5437 - val_accuracy: 0.0950\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5164 - accuracy: 0.4681 - val_loss: 3.5365 - val_accuracy: 0.0972\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5195 - accuracy: 0.4651 - val_loss: 3.5175 - val_accuracy: 0.1015\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5105 - accuracy: 0.4692 - val_loss: 3.5052 - val_accuracy: 0.1042\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5204 - accuracy: 0.4669 - val_loss: 3.5624 - val_accuracy: 0.0975\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5253 - accuracy: 0.4608 - val_loss: 3.4966 - val_accuracy: 0.1021\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5118 - accuracy: 0.4694 - val_loss: 3.4306 - val_accuracy: 0.1094\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5185 - accuracy: 0.4670 - val_loss: 3.4753 - val_accuracy: 0.1058\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5227 - accuracy: 0.4663 - val_loss: 3.5503 - val_accuracy: 0.0984\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5233 - accuracy: 0.4623 - val_loss: 3.4966 - val_accuracy: 0.1006\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5102 - accuracy: 0.4698 - val_loss: 3.5111 - val_accuracy: 0.1034\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5154 - accuracy: 0.4634 - val_loss: 3.5136 - val_accuracy: 0.0994\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5109 - accuracy: 0.4689 - val_loss: 3.4604 - val_accuracy: 0.1048\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5196 - accuracy: 0.4678 - val_loss: 3.5191 - val_accuracy: 0.1000\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5153 - accuracy: 0.4650 - val_loss: 3.5111 - val_accuracy: 0.1003\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5173 - accuracy: 0.4669 - val_loss: 3.5116 - val_accuracy: 0.0972\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5028 - accuracy: 0.4732 - val_loss: 3.5384 - val_accuracy: 0.0961\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5064 - accuracy: 0.4717 - val_loss: 3.5175 - val_accuracy: 0.1011\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5207 - accuracy: 0.4621 - val_loss: 3.4950 - val_accuracy: 0.1063\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5178 - accuracy: 0.4627 - val_loss: 3.5077 - val_accuracy: 0.1060\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5155 - accuracy: 0.4624 - val_loss: 3.4886 - val_accuracy: 0.1033\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5093 - accuracy: 0.4672 - val_loss: 3.4934 - val_accuracy: 0.1004\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5037 - accuracy: 0.4701 - val_loss: 3.5217 - val_accuracy: 0.1023\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5119 - accuracy: 0.4688 - val_loss: 3.5415 - val_accuracy: 0.1006\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5160 - accuracy: 0.4634 - val_loss: 3.5170 - val_accuracy: 0.1097\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5090 - accuracy: 0.4693 - val_loss: 3.5342 - val_accuracy: 0.1003\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5198 - accuracy: 0.4629 - val_loss: 3.5272 - val_accuracy: 0.1005\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5158 - accuracy: 0.4648 - val_loss: 3.4922 - val_accuracy: 0.1030\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5126 - accuracy: 0.4679 - val_loss: 3.5164 - val_accuracy: 0.0989\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5189 - accuracy: 0.4638 - val_loss: 3.5010 - val_accuracy: 0.1019\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5042 - accuracy: 0.4715 - val_loss: 3.5214 - val_accuracy: 0.0994\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5007 - accuracy: 0.4729 - val_loss: 3.4760 - val_accuracy: 0.1101\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5102 - accuracy: 0.4672 - val_loss: 3.5327 - val_accuracy: 0.1003\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5072 - accuracy: 0.4700 - val_loss: 3.4673 - val_accuracy: 0.1039\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5104 - accuracy: 0.4715 - val_loss: 3.5608 - val_accuracy: 0.1013\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5207 - accuracy: 0.4670 - val_loss: 3.5417 - val_accuracy: 0.0974\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5106 - accuracy: 0.4697 - val_loss: 3.5221 - val_accuracy: 0.1010\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5162 - accuracy: 0.4640 - val_loss: 3.5364 - val_accuracy: 0.1031\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5081 - accuracy: 0.4685 - val_loss: 3.4998 - val_accuracy: 0.1073\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5128 - accuracy: 0.4667 - val_loss: 3.5428 - val_accuracy: 0.1006\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5084 - accuracy: 0.4660 - val_loss: 3.5325 - val_accuracy: 0.1030\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5039 - accuracy: 0.4703 - val_loss: 3.5229 - val_accuracy: 0.1071\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5080 - accuracy: 0.4691 - val_loss: 3.5151 - val_accuracy: 0.1057\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5001 - accuracy: 0.4721 - val_loss: 3.4940 - val_accuracy: 0.1043\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5051 - accuracy: 0.4694 - val_loss: 3.5331 - val_accuracy: 0.1015\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4990 - accuracy: 0.4720 - val_loss: 3.5655 - val_accuracy: 0.1043\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5058 - accuracy: 0.4688 - val_loss: 3.5472 - val_accuracy: 0.0999\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5121 - accuracy: 0.4651 - val_loss: 3.5421 - val_accuracy: 0.0996\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5048 - accuracy: 0.4690 - val_loss: 3.5355 - val_accuracy: 0.1029\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5109 - accuracy: 0.4661 - val_loss: 3.5071 - val_accuracy: 0.1033\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5092 - accuracy: 0.4697 - val_loss: 3.5582 - val_accuracy: 0.1027\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5019 - accuracy: 0.4728 - val_loss: 3.5308 - val_accuracy: 0.1018\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5021 - accuracy: 0.4714 - val_loss: 3.5474 - val_accuracy: 0.0987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldcCchKFLQpX"
      },
      "source": [
        "# The codes below this section will be the CNN network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuPe2pl1ZAJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ba479b-c169-4d8c-86a4-89a70c84134c"
      },
      "source": [
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Training matrix shape (60000, 28, 28, 1)\n",
            "Testing matrix shape (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jeYSTHO5ZAJO"
      },
      "source": [
        "# one-hot format classes\n",
        "\n",
        "nb_classes = 10 # number of unique digits\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Y9Q0wQ9BZAJO"
      },
      "source": [
        "def build_model(first_dense=512):\n",
        "  model = Sequential()                                 # Linear stacking of layers\n",
        "  # Convolution Layer 1\n",
        "  model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  convLayer01 = Activation('relu')                     # activation\n",
        "  model.add(convLayer01)\n",
        "\n",
        "  # Convolution Layer 2\n",
        "  model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  model.add(Activation('relu'))                        # activation\n",
        "  convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "  model.add(convLayer02)\n",
        "\n",
        "  # Convolution Layer 3\n",
        "  model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  convLayer03 = Activation('relu')                     # activation\n",
        "  model.add(convLayer03)\n",
        "\n",
        "  # Convolution Layer 4\n",
        "  model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  model.add(Activation('relu'))                        # activation\n",
        "  convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "  model.add(convLayer04)\n",
        "  model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
        "\n",
        "  # Fully Connected Layer 5\n",
        "  model.add(Dense(first_dense))                                # 512 FCN nodes\n",
        "  model.add(BatchNormalization())                      # normalization\n",
        "  model.add(Activation('relu'))                        # activation\n",
        "\n",
        "  # Fully Connected Layer 6\n",
        "  model.add(Dense(10))                                 # final 10 FCN nodes\n",
        "  model.add(Activation('softmax'))                     # softmax activationss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKKoJXKaZAJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf111382-4ddf-4257-ba6e-a04fd395e006"
      },
      "source": [
        "CNN_model = build_model()\n",
        "print(CNN_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 597,738\n",
            "Trainable params: 596,330\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXjW6lZ7ZAJP"
      },
      "source": [
        "CNN_history = CNN_model.fit(x=X_train, y=Y_train, epochs=50, steps_per_epoch=100, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-7ugepG-HGH"
      },
      "source": [
        "#Third Empirical Study: Unlabeled data take the majority, and verify the pretrained steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3AD3Tmk-R7S"
      },
      "source": [
        "\"\"\"\n",
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "#Flatten the X data for PCA features\n",
        "X_train_Flatten = X_train.reshape(60000, 28*28)\n",
        "X_test_Flatten = X_test.reshape(10000, 28*28)\n",
        "\n",
        "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "nb_classes = 10 # number of unique digits\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\"\"\"\n",
        "\n",
        "#Futher more, decompose the train set to unlabel train set and label train set. We will try to tranfer the PCA from unlabel dataset to the label dataset.\n",
        "\n",
        "X_unlabel, X_label, y_unlabel, y_label = train_test_split(X_train, y_train, test_size = 0.5)\n",
        "X_unlabel_Flatten = X_unlabel.reshape(30000, 28*28)\n",
        "X_label_Flatten = X_label.reshape(30000, 28*28)\n",
        "\n",
        "Y_unlabel = np_utils.to_categorical(y_unlabel, nb_classes)\n",
        "Y_label = np_utils.to_categorical(y_label, nb_classes)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5shvZswf8p0"
      },
      "source": [
        "#Do the PCA here\n",
        "obj_kpca = KPCA(n_components=32, kernel=\"rbf\")\n",
        "transformed_X = obj_kpca.fit_transform(X_label_Flatten)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb4EyoOr_a51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d991e941-57f5-4f7c-b1d2-9fe7d19a3322"
      },
      "source": [
        "#Do the PCA here\n",
        "obj_pca_naive = PCA(n_components=32)\n",
        "obj_pca_naive.fit(X_label_Flatten)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=32, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgBf8dIAmFr",
        "outputId": "bb2d9388-8aa1-4092-c2a8-b4cc1e9b52d7"
      },
      "source": [
        "new_X_train = X_label_Flatten @ obj_pca_naive.components_.T #Map the unlabel PCs with the labeled dataset\n",
        "print(new_X_train.shape)\n",
        "print(transformed_X.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 32)\n",
            "(30000, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LckcR-0LA66m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cdd5ee8-405f-4392-f47a-b75514c27e31"
      },
      "source": [
        "K_pca = build_model_single_dense(32)\n",
        "Kpca_history = K_pca.fit(x=transformed_X, y=Y_label, epochs=50, validation_split=0.2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 3s 2ms/step - loss: 2.0382 - accuracy: 0.4486 - val_loss: 1.0003 - val_accuracy: 0.7962\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.8484 - accuracy: 0.8181 - val_loss: 0.5715 - val_accuracy: 0.8632\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.8650 - val_loss: 0.4584 - val_accuracy: 0.8757\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4456 - accuracy: 0.8772 - val_loss: 0.4159 - val_accuracy: 0.8845\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4090 - accuracy: 0.8828 - val_loss: 0.3929 - val_accuracy: 0.8872\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3821 - accuracy: 0.8901 - val_loss: 0.3812 - val_accuracy: 0.8888\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3748 - accuracy: 0.8898 - val_loss: 0.3693 - val_accuracy: 0.8915\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3567 - accuracy: 0.8960 - val_loss: 0.3616 - val_accuracy: 0.8927\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3631 - accuracy: 0.8933 - val_loss: 0.3555 - val_accuracy: 0.8952\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3366 - accuracy: 0.8997 - val_loss: 0.3488 - val_accuracy: 0.8973\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3253 - accuracy: 0.9027 - val_loss: 0.3424 - val_accuracy: 0.8997\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3299 - accuracy: 0.9025 - val_loss: 0.3374 - val_accuracy: 0.9013\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3268 - accuracy: 0.9052 - val_loss: 0.3316 - val_accuracy: 0.9043\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3085 - accuracy: 0.9097 - val_loss: 0.3259 - val_accuracy: 0.9057\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3125 - accuracy: 0.9083 - val_loss: 0.3192 - val_accuracy: 0.9072\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3107 - accuracy: 0.9081 - val_loss: 0.3152 - val_accuracy: 0.9095\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3086 - accuracy: 0.9118 - val_loss: 0.3092 - val_accuracy: 0.9102\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3038 - accuracy: 0.9109 - val_loss: 0.3074 - val_accuracy: 0.9115\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3002 - accuracy: 0.9135 - val_loss: 0.3002 - val_accuracy: 0.9115\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2815 - accuracy: 0.9185 - val_loss: 0.2953 - val_accuracy: 0.9123\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2785 - accuracy: 0.9189 - val_loss: 0.2899 - val_accuracy: 0.9132\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2736 - accuracy: 0.9208 - val_loss: 0.2845 - val_accuracy: 0.9148\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2815 - accuracy: 0.9170 - val_loss: 0.2799 - val_accuracy: 0.9162\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2647 - accuracy: 0.9228 - val_loss: 0.2775 - val_accuracy: 0.9188\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2557 - accuracy: 0.9264 - val_loss: 0.2710 - val_accuracy: 0.9208\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2521 - accuracy: 0.9267 - val_loss: 0.2663 - val_accuracy: 0.9235\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2519 - accuracy: 0.9251 - val_loss: 0.2614 - val_accuracy: 0.9253\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2383 - accuracy: 0.9305 - val_loss: 0.2589 - val_accuracy: 0.9258\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2346 - accuracy: 0.9320 - val_loss: 0.2541 - val_accuracy: 0.9272\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2327 - accuracy: 0.9341 - val_loss: 0.2506 - val_accuracy: 0.9267\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2232 - accuracy: 0.9328 - val_loss: 0.2451 - val_accuracy: 0.9287\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2299 - accuracy: 0.9337 - val_loss: 0.2420 - val_accuracy: 0.9297\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2169 - accuracy: 0.9373 - val_loss: 0.2376 - val_accuracy: 0.9300\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2193 - accuracy: 0.9368 - val_loss: 0.2356 - val_accuracy: 0.9312\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2126 - accuracy: 0.9378 - val_loss: 0.2334 - val_accuracy: 0.9288\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2076 - accuracy: 0.9399 - val_loss: 0.2280 - val_accuracy: 0.9322\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2153 - accuracy: 0.9390 - val_loss: 0.2252 - val_accuracy: 0.9348\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2055 - accuracy: 0.9406 - val_loss: 0.2238 - val_accuracy: 0.9340\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2024 - accuracy: 0.9423 - val_loss: 0.2215 - val_accuracy: 0.9333\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2006 - accuracy: 0.9437 - val_loss: 0.2181 - val_accuracy: 0.9372\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1878 - accuracy: 0.9452 - val_loss: 0.2158 - val_accuracy: 0.9363\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1936 - accuracy: 0.9440 - val_loss: 0.2137 - val_accuracy: 0.9370\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1844 - accuracy: 0.9466 - val_loss: 0.2108 - val_accuracy: 0.9370\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1895 - accuracy: 0.9432 - val_loss: 0.2099 - val_accuracy: 0.9385\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1799 - accuracy: 0.9478 - val_loss: 0.2076 - val_accuracy: 0.9385\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1821 - accuracy: 0.9484 - val_loss: 0.2046 - val_accuracy: 0.9408\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1854 - accuracy: 0.9459 - val_loss: 0.2031 - val_accuracy: 0.9407\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1809 - accuracy: 0.9485 - val_loss: 0.2027 - val_accuracy: 0.9415\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1764 - accuracy: 0.9502 - val_loss: 0.2010 - val_accuracy: 0.9398\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1707 - accuracy: 0.9481 - val_loss: 0.1982 - val_accuracy: 0.9425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER7inAvxCKUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b76e5e-5716-4d15-b756-8240d85adfa5"
      },
      "source": [
        "naive_pca = build_model_single_dense(32)\n",
        "naive_pca_history = naive_pca.fit(x=new_X_train, y=Y_label, epochs=50, validation_split=0.2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.4953 - accuracy: 0.5233 - val_loss: 0.4348 - val_accuracy: 0.8783\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3948 - accuracy: 0.8859 - val_loss: 0.3507 - val_accuracy: 0.8980\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3344 - accuracy: 0.9007 - val_loss: 0.3158 - val_accuracy: 0.9062\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2926 - accuracy: 0.9156 - val_loss: 0.2859 - val_accuracy: 0.9130\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2588 - accuracy: 0.9253 - val_loss: 0.2673 - val_accuracy: 0.9242\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2402 - accuracy: 0.9303 - val_loss: 0.2562 - val_accuracy: 0.9270\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2279 - accuracy: 0.9335 - val_loss: 0.2333 - val_accuracy: 0.9322\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1996 - accuracy: 0.9418 - val_loss: 0.2252 - val_accuracy: 0.9368\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1970 - accuracy: 0.9405 - val_loss: 0.2180 - val_accuracy: 0.9362\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1837 - accuracy: 0.9447 - val_loss: 0.2124 - val_accuracy: 0.9377\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1824 - accuracy: 0.9453 - val_loss: 0.2091 - val_accuracy: 0.9380\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1704 - accuracy: 0.9494 - val_loss: 0.1992 - val_accuracy: 0.9428\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1687 - accuracy: 0.9511 - val_loss: 0.1985 - val_accuracy: 0.9432\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1682 - accuracy: 0.9512 - val_loss: 0.1906 - val_accuracy: 0.9455\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1614 - accuracy: 0.9519 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1463 - accuracy: 0.9560 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1482 - accuracy: 0.9561 - val_loss: 0.1905 - val_accuracy: 0.9465\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1480 - accuracy: 0.9555 - val_loss: 0.1836 - val_accuracy: 0.9457\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1429 - accuracy: 0.9571 - val_loss: 0.1810 - val_accuracy: 0.9478\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1455 - accuracy: 0.9573 - val_loss: 0.1825 - val_accuracy: 0.9468\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1436 - accuracy: 0.9588 - val_loss: 0.1790 - val_accuracy: 0.9495\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1353 - accuracy: 0.9600 - val_loss: 0.1775 - val_accuracy: 0.9512\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1366 - accuracy: 0.9574 - val_loss: 0.1780 - val_accuracy: 0.9490\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1326 - accuracy: 0.9601 - val_loss: 0.1772 - val_accuracy: 0.9510\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1292 - accuracy: 0.9609 - val_loss: 0.1743 - val_accuracy: 0.9502\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1322 - accuracy: 0.9613 - val_loss: 0.1738 - val_accuracy: 0.9517\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1286 - accuracy: 0.9616 - val_loss: 0.1709 - val_accuracy: 0.9503\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1265 - accuracy: 0.9641 - val_loss: 0.1701 - val_accuracy: 0.9532\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1290 - accuracy: 0.9614 - val_loss: 0.1727 - val_accuracy: 0.9503\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1203 - accuracy: 0.9635 - val_loss: 0.1703 - val_accuracy: 0.9528\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1243 - accuracy: 0.9630 - val_loss: 0.1719 - val_accuracy: 0.9508\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.1225 - accuracy: 0.9641 - val_loss: 0.1707 - val_accuracy: 0.9515\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1307 - accuracy: 0.9594 - val_loss: 0.1721 - val_accuracy: 0.9515\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1143 - accuracy: 0.9652 - val_loss: 0.1668 - val_accuracy: 0.9540\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1155 - accuracy: 0.9654 - val_loss: 0.1751 - val_accuracy: 0.9510\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1218 - accuracy: 0.9626 - val_loss: 0.1707 - val_accuracy: 0.9535\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1205 - accuracy: 0.9625 - val_loss: 0.1688 - val_accuracy: 0.9520\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1186 - accuracy: 0.9659 - val_loss: 0.1695 - val_accuracy: 0.9510\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1147 - accuracy: 0.9661 - val_loss: 0.1704 - val_accuracy: 0.9517\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1147 - accuracy: 0.9649 - val_loss: 0.1651 - val_accuracy: 0.9530\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1093 - accuracy: 0.9667 - val_loss: 0.1664 - val_accuracy: 0.9515\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1109 - accuracy: 0.9655 - val_loss: 0.1714 - val_accuracy: 0.9527\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1036 - accuracy: 0.9687 - val_loss: 0.1677 - val_accuracy: 0.9525\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1078 - accuracy: 0.9672 - val_loss: 0.1693 - val_accuracy: 0.9512\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1113 - accuracy: 0.9659 - val_loss: 0.1690 - val_accuracy: 0.9525\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1050 - accuracy: 0.9682 - val_loss: 0.1702 - val_accuracy: 0.9523\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1028 - accuracy: 0.9709 - val_loss: 0.1669 - val_accuracy: 0.9532\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1028 - accuracy: 0.9696 - val_loss: 0.1686 - val_accuracy: 0.9508\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1081 - accuracy: 0.9683 - val_loss: 0.1674 - val_accuracy: 0.9540\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1027 - accuracy: 0.9684 - val_loss: 0.1752 - val_accuracy: 0.9505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jE6L4UxFCrQ8",
        "outputId": "0fe8cb30-edcc-4c95-99c3-2904991b451a"
      },
      "source": [
        "%matplotlib inline\n",
        "plt.plot(Kpca_history.history['accuracy'])\n",
        "plt.plot(Kpca_history.history['val_accuracy'])\n",
        "plt.plot(naive_pca_history.history['accuracy'])\n",
        "plt.plot(naive_pca_history.history['val_accuracy'])\n",
        "plt.title('compare model')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['K_pca_accuracy', 'K_pca_val_accuracy', 'naive_pca_accuracy', 'naive_pca_val_accuracy'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBVWJ5DiNP1A"
      },
      "source": [
        "X_random_train = unlabel_X.reshape(48000, 28, 28, 1)\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "X_CNN_train = label_X.reshape(12000, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il818OLeOIMo"
      },
      "source": [
        "CNN_model = build_model()\n",
        "CNN_random_history = CNN_model.fit(x=X_random_train, y = Y_random, epochs=50, steps_per_epoch=200, batch_size=200, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JyTTsRoT65Y"
      },
      "source": [
        "print(CNN_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKnu4GV8UBGg"
      },
      "source": [
        "for layer in CNN_model.layers[:]:\n",
        "  layer.trainable = False\n",
        "\n",
        "for i in range(-5, 0):\n",
        "  CNN_model.layers[i].trainable= True\n",
        "\n",
        "model_status(CNN_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rifH0oRWNdO"
      },
      "source": [
        "X_label = label_X.reshape(12000, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ybQHJD1V0H6"
      },
      "source": [
        "CNN_finetune_history = CNN_model.fit(x=X_label, y = Y_label, epochs=50, steps_per_epoch=100, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}