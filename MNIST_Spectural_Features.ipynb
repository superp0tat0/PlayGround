{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST Spectural_Features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Tensorflow (GPU)",
      "language": "python",
      "name": "py3.6-tfgpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superp0tat0/PlayGround/blob/master/MNIST_Spectural_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHijRDhe8AQ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ1paqfWZAJA"
      },
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random                        # for generating random numbers\n",
        "\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.utils import np_utils                         # NumPy related tools\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import some additional tools\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "def model_status(model):\n",
        "    for layer in model.layers:\n",
        "      print(layer, layer.trainable)\n",
        "\n",
        "def build_model_single_dense(first_layer_neuron = 32):\n",
        "  model = Sequential()                                 # Linear stacking of layers\n",
        "  model.add(Dense(first_layer_neuron))                \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(10))                                 # final 10 FCN nodes\n",
        "  model.add(Activation('softmax'))                     # softmax activation\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def build_model_complex_dense():\n",
        "  model = Sequential()                                 # Linear stacking of layers\n",
        "  model.add(Dense(32))\n",
        "  model.add(BatchNormalization())             \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(64))\n",
        "  model.add(BatchNormalization())             \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(128))\n",
        "  model.add(BatchNormalization())             \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(64))\n",
        "  model.add(BatchNormalization())             \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(32))\n",
        "  model.add(BatchNormalization())             \n",
        "  model.add(Activation('relu'))                     # relu activation\n",
        "\n",
        "  model.add(Dense(10))                                 # final 10 FCN nodes\n",
        "  model.add(Activation('softmax'))                     # softmax activation\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vW96zcCvZAJN"
      },
      "source": [
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "#Flatten the X data for PCA features\n",
        "X_train_Flatten = X_train.reshape(60000, 28*28)\n",
        "X_test_Flatten = X_test.reshape(10000, 28*28)\n",
        "\n",
        "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "nb_classes = 10 # number of unique digits\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "y_random = np.array([random.randint(0,9) for i in range(60000)])\n",
        "Y_random = np_utils.to_categorical(y_random, nb_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCTVg5DYLo43",
        "outputId": "b1bfa88f-35f3-4a12-d2aa-b26a353d81ee"
      },
      "source": [
        "#Do the PCA here\n",
        "obj_pca = PCA(n_components=60)\n",
        "obj_pca.fit(X_train_Flatten)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=60, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "316h6rjXKElv",
        "outputId": "c55f72d9-2782-4f33-febd-a4d334a18510"
      },
      "source": [
        "pcs = obj_pca.components_.reshape(60,28,28)\n",
        "print(pcs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeRnZ6lFLADu"
      },
      "source": [
        "# Empirical Study 1\n",
        "What does the Principal Components look like for the whole dataset?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmewAuEHJgTk"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (30,12) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(32):\n",
        "    plt.subplot(4,8,i+1)\n",
        "    plt.imshow(pcs[i], cmap='gray', interpolation='none')\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAqWZnnPwWIa"
      },
      "source": [
        "# Empirical Study 2a\n",
        "Will PCA benefit of convergence? Yes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zg-sjNwnXJy",
        "outputId": "5d25b510-3d12-4411-83bd-1f31a0946c47"
      },
      "source": [
        "# Treat the new PCs as the weights.\n",
        "new_X_train = X_train_Flatten @ obj_pca.components_.T\n",
        "new_X_test = X_test_Flatten @ obj_pca.components_.T\n",
        "print(new_X_train.shape)\n",
        "print(new_X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 60)\n",
            "(10000, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2wu6Ex0sn8dJ"
      },
      "source": [
        "pca_model = build_model_single_dense(32)\n",
        "pca_history = pca_model.fit(x=new_X_train, y=Y_train, epochs=50, steps_per_epoch=100, validation_data=(new_X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAjm6zmowsRu"
      },
      "source": [
        "naive_dense = build_model_single_dense(32)\n",
        "naive_history = naive_dense.fit(x=X_train_Flatten, y=Y_train, epochs=50, steps_per_epoch=100, validation_data=(X_test_Flatten, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "coga7IutqqpB",
        "outputId": "a68dd8b1-be81-4641-ea53-02b1c4acb613"
      },
      "source": [
        "%matplotlib inline\n",
        "plt.plot(pca_history.history['accuracy'])\n",
        "plt.plot(pca_history.history['val_accuracy'])\n",
        "plt.plot(naive_history.history['accuracy'])\n",
        "plt.plot(naive_history.history['val_accuracy'])\n",
        "plt.title('compare model')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['pca_accuracy', 'pca_val_accuracy', 'naive_dence_accuracy', 'naive_dense_val_accuracy'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4yCFngZ-NoY"
      },
      "source": [
        "# Empirical Study 2b\n",
        "What does the simple dense layer work with the random labeled datasets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOKHV2Al-W6T",
        "outputId": "3f74ee01-60b9-4668-a002-aaa85742ff41"
      },
      "source": [
        "random_dense = build_model_complex_dense()\n",
        "random_history = random_dense.fit(x = X_train_Flatten, y=Y_random, epochs=500, steps_per_epoch=100, validation_data=(X_test_Flatten, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 2s 14ms/step - loss: 2.4649 - accuracy: 0.0996 - val_loss: 2.3107 - val_accuracy: 0.1156\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.3020 - accuracy: 0.1189 - val_loss: 2.3390 - val_accuracy: 0.0862\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2879 - accuracy: 0.1291 - val_loss: 2.3172 - val_accuracy: 0.1035\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2808 - accuracy: 0.1361 - val_loss: 2.3007 - val_accuracy: 0.1156\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2724 - accuracy: 0.1439 - val_loss: 2.3041 - val_accuracy: 0.1249\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2640 - accuracy: 0.1533 - val_loss: 2.3255 - val_accuracy: 0.1033\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2594 - accuracy: 0.1553 - val_loss: 2.3691 - val_accuracy: 0.0989\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2471 - accuracy: 0.1620 - val_loss: 2.3424 - val_accuracy: 0.1022\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2397 - accuracy: 0.1690 - val_loss: 2.3804 - val_accuracy: 0.0932\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2305 - accuracy: 0.1726 - val_loss: 2.3427 - val_accuracy: 0.1072\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2183 - accuracy: 0.1856 - val_loss: 2.3538 - val_accuracy: 0.1197\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2062 - accuracy: 0.1887 - val_loss: 2.3418 - val_accuracy: 0.1146\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1980 - accuracy: 0.1933 - val_loss: 2.3609 - val_accuracy: 0.1170\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1877 - accuracy: 0.1980 - val_loss: 2.3827 - val_accuracy: 0.1054\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1744 - accuracy: 0.2044 - val_loss: 2.3669 - val_accuracy: 0.1187\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1666 - accuracy: 0.2120 - val_loss: 2.3959 - val_accuracy: 0.1062\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1550 - accuracy: 0.2178 - val_loss: 2.4127 - val_accuracy: 0.1050\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1487 - accuracy: 0.2191 - val_loss: 2.4075 - val_accuracy: 0.1139\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1385 - accuracy: 0.2253 - val_loss: 2.4421 - val_accuracy: 0.1041\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1222 - accuracy: 0.2315 - val_loss: 2.4499 - val_accuracy: 0.0981\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1138 - accuracy: 0.2385 - val_loss: 2.4751 - val_accuracy: 0.1066\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1045 - accuracy: 0.2409 - val_loss: 2.4817 - val_accuracy: 0.1090\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0975 - accuracy: 0.2440 - val_loss: 2.4782 - val_accuracy: 0.1085\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0834 - accuracy: 0.2502 - val_loss: 2.5080 - val_accuracy: 0.0974\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0801 - accuracy: 0.2509 - val_loss: 2.4964 - val_accuracy: 0.1061\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0632 - accuracy: 0.2602 - val_loss: 2.5158 - val_accuracy: 0.0980\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0581 - accuracy: 0.2629 - val_loss: 2.4966 - val_accuracy: 0.1072\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0453 - accuracy: 0.2708 - val_loss: 2.5231 - val_accuracy: 0.1070\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0401 - accuracy: 0.2703 - val_loss: 2.5429 - val_accuracy: 0.1035\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0297 - accuracy: 0.2750 - val_loss: 2.5351 - val_accuracy: 0.1040\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0263 - accuracy: 0.2783 - val_loss: 2.5874 - val_accuracy: 0.1009\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0138 - accuracy: 0.2827 - val_loss: 2.5543 - val_accuracy: 0.1068\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0080 - accuracy: 0.2857 - val_loss: 2.6068 - val_accuracy: 0.0976\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9985 - accuracy: 0.2860 - val_loss: 2.5689 - val_accuracy: 0.1070\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9844 - accuracy: 0.2940 - val_loss: 2.5689 - val_accuracy: 0.1115\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9808 - accuracy: 0.2940 - val_loss: 2.6138 - val_accuracy: 0.1066\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9740 - accuracy: 0.2954 - val_loss: 2.5857 - val_accuracy: 0.1078\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9713 - accuracy: 0.2960 - val_loss: 2.6244 - val_accuracy: 0.1049\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9572 - accuracy: 0.3036 - val_loss: 2.6130 - val_accuracy: 0.1093\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9546 - accuracy: 0.3052 - val_loss: 2.6183 - val_accuracy: 0.1037\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9493 - accuracy: 0.3042 - val_loss: 2.6766 - val_accuracy: 0.1001\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9390 - accuracy: 0.3113 - val_loss: 2.6584 - val_accuracy: 0.1040\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9425 - accuracy: 0.3114 - val_loss: 2.6920 - val_accuracy: 0.0996\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9334 - accuracy: 0.3145 - val_loss: 2.6727 - val_accuracy: 0.1066\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9240 - accuracy: 0.3173 - val_loss: 2.6366 - val_accuracy: 0.1116\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9270 - accuracy: 0.3154 - val_loss: 2.6355 - val_accuracy: 0.1153\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9141 - accuracy: 0.3242 - val_loss: 2.6862 - val_accuracy: 0.1059\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9144 - accuracy: 0.3223 - val_loss: 2.7136 - val_accuracy: 0.1016\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9052 - accuracy: 0.3232 - val_loss: 2.7035 - val_accuracy: 0.1017\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.8970 - accuracy: 0.3275 - val_loss: 2.7330 - val_accuracy: 0.1037\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8960 - accuracy: 0.3260 - val_loss: 2.7605 - val_accuracy: 0.1001\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8968 - accuracy: 0.3263 - val_loss: 2.7335 - val_accuracy: 0.1027\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8906 - accuracy: 0.3290 - val_loss: 2.7093 - val_accuracy: 0.1057\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8779 - accuracy: 0.3328 - val_loss: 2.6752 - val_accuracy: 0.1158\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8847 - accuracy: 0.3335 - val_loss: 2.7855 - val_accuracy: 0.0926\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8750 - accuracy: 0.3374 - val_loss: 2.7744 - val_accuracy: 0.0953\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8675 - accuracy: 0.3404 - val_loss: 2.7861 - val_accuracy: 0.1003\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8663 - accuracy: 0.3406 - val_loss: 2.7592 - val_accuracy: 0.1024\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8630 - accuracy: 0.3409 - val_loss: 2.7772 - val_accuracy: 0.0988\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8588 - accuracy: 0.3445 - val_loss: 2.7859 - val_accuracy: 0.1050\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8527 - accuracy: 0.3430 - val_loss: 2.8009 - val_accuracy: 0.0998\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8485 - accuracy: 0.3451 - val_loss: 2.7758 - val_accuracy: 0.1100\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8449 - accuracy: 0.3463 - val_loss: 2.7976 - val_accuracy: 0.1041\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8527 - accuracy: 0.3424 - val_loss: 2.8486 - val_accuracy: 0.0983\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8374 - accuracy: 0.3514 - val_loss: 2.8248 - val_accuracy: 0.0997\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8327 - accuracy: 0.3517 - val_loss: 2.8260 - val_accuracy: 0.0997\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8328 - accuracy: 0.3515 - val_loss: 2.8180 - val_accuracy: 0.1041\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8307 - accuracy: 0.3524 - val_loss: 2.8487 - val_accuracy: 0.0997\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8247 - accuracy: 0.3530 - val_loss: 2.8266 - val_accuracy: 0.1051\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8197 - accuracy: 0.3582 - val_loss: 2.7831 - val_accuracy: 0.1099\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8206 - accuracy: 0.3538 - val_loss: 2.8416 - val_accuracy: 0.1011\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8267 - accuracy: 0.3540 - val_loss: 2.8190 - val_accuracy: 0.1023\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8089 - accuracy: 0.3634 - val_loss: 2.8298 - val_accuracy: 0.1052\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8152 - accuracy: 0.3569 - val_loss: 2.8684 - val_accuracy: 0.1013\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.8110 - accuracy: 0.3576 - val_loss: 2.9140 - val_accuracy: 0.0972\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8063 - accuracy: 0.3600 - val_loss: 2.8471 - val_accuracy: 0.1105\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8035 - accuracy: 0.3637 - val_loss: 2.8279 - val_accuracy: 0.1087\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8030 - accuracy: 0.3632 - val_loss: 2.8922 - val_accuracy: 0.1035\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8013 - accuracy: 0.3634 - val_loss: 2.8796 - val_accuracy: 0.1050\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7945 - accuracy: 0.3679 - val_loss: 2.8526 - val_accuracy: 0.1116\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7894 - accuracy: 0.3697 - val_loss: 2.8499 - val_accuracy: 0.1091\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7903 - accuracy: 0.3688 - val_loss: 2.9149 - val_accuracy: 0.0971\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7879 - accuracy: 0.3700 - val_loss: 2.8762 - val_accuracy: 0.1068\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7844 - accuracy: 0.3710 - val_loss: 2.8840 - val_accuracy: 0.1054\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7770 - accuracy: 0.3729 - val_loss: 2.9078 - val_accuracy: 0.1056\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7785 - accuracy: 0.3711 - val_loss: 2.9074 - val_accuracy: 0.1020\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7744 - accuracy: 0.3737 - val_loss: 2.8873 - val_accuracy: 0.1077\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7706 - accuracy: 0.3749 - val_loss: 2.9517 - val_accuracy: 0.0942\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7759 - accuracy: 0.3698 - val_loss: 2.9029 - val_accuracy: 0.1041\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7599 - accuracy: 0.3788 - val_loss: 2.9242 - val_accuracy: 0.1063\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7774 - accuracy: 0.3713 - val_loss: 2.9296 - val_accuracy: 0.1010\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7628 - accuracy: 0.3784 - val_loss: 2.9065 - val_accuracy: 0.1056\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7626 - accuracy: 0.3779 - val_loss: 2.9441 - val_accuracy: 0.1020\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7601 - accuracy: 0.3807 - val_loss: 2.9693 - val_accuracy: 0.1003\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7625 - accuracy: 0.3793 - val_loss: 2.9433 - val_accuracy: 0.1001\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7567 - accuracy: 0.3791 - val_loss: 2.9384 - val_accuracy: 0.1080\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7534 - accuracy: 0.3797 - val_loss: 2.9399 - val_accuracy: 0.1048\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7487 - accuracy: 0.3803 - val_loss: 2.9572 - val_accuracy: 0.1044\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7445 - accuracy: 0.3868 - val_loss: 2.9865 - val_accuracy: 0.0981\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.7491 - accuracy: 0.3822 - val_loss: 2.9677 - val_accuracy: 0.0965\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7480 - accuracy: 0.3852 - val_loss: 2.9947 - val_accuracy: 0.0941\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7384 - accuracy: 0.3870 - val_loss: 2.9570 - val_accuracy: 0.1100\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7394 - accuracy: 0.3904 - val_loss: 2.9766 - val_accuracy: 0.1032\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7444 - accuracy: 0.3842 - val_loss: 3.0065 - val_accuracy: 0.0975\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7416 - accuracy: 0.3884 - val_loss: 2.9955 - val_accuracy: 0.1018\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7383 - accuracy: 0.3860 - val_loss: 2.9977 - val_accuracy: 0.1012\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7297 - accuracy: 0.3898 - val_loss: 2.9536 - val_accuracy: 0.1072\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7234 - accuracy: 0.3954 - val_loss: 2.9965 - val_accuracy: 0.0956\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7291 - accuracy: 0.3891 - val_loss: 3.0078 - val_accuracy: 0.0970\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7277 - accuracy: 0.3886 - val_loss: 3.0124 - val_accuracy: 0.1001\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7259 - accuracy: 0.3942 - val_loss: 3.0191 - val_accuracy: 0.1014\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7316 - accuracy: 0.3875 - val_loss: 3.0223 - val_accuracy: 0.0973\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7250 - accuracy: 0.3916 - val_loss: 2.9796 - val_accuracy: 0.1082\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7139 - accuracy: 0.3959 - val_loss: 2.9843 - val_accuracy: 0.1053\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7174 - accuracy: 0.3960 - val_loss: 3.0336 - val_accuracy: 0.0977\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7141 - accuracy: 0.3978 - val_loss: 3.0584 - val_accuracy: 0.0949\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7195 - accuracy: 0.3931 - val_loss: 3.0565 - val_accuracy: 0.1006\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7156 - accuracy: 0.3956 - val_loss: 3.0321 - val_accuracy: 0.1014\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7188 - accuracy: 0.3934 - val_loss: 2.9927 - val_accuracy: 0.1093\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7085 - accuracy: 0.3994 - val_loss: 3.0584 - val_accuracy: 0.1013\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7164 - accuracy: 0.3936 - val_loss: 2.9906 - val_accuracy: 0.1074\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7014 - accuracy: 0.4010 - val_loss: 3.0472 - val_accuracy: 0.0985\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7097 - accuracy: 0.3982 - val_loss: 3.0804 - val_accuracy: 0.0999\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7105 - accuracy: 0.3974 - val_loss: 2.9772 - val_accuracy: 0.1122\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7032 - accuracy: 0.4012 - val_loss: 3.0383 - val_accuracy: 0.1032\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7012 - accuracy: 0.4038 - val_loss: 3.0748 - val_accuracy: 0.0980\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7040 - accuracy: 0.3999 - val_loss: 2.9967 - val_accuracy: 0.1123\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6962 - accuracy: 0.4016 - val_loss: 3.0348 - val_accuracy: 0.1047\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7046 - accuracy: 0.4005 - val_loss: 3.0082 - val_accuracy: 0.1053\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6936 - accuracy: 0.4010 - val_loss: 3.0705 - val_accuracy: 0.1001\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6940 - accuracy: 0.4054 - val_loss: 3.0833 - val_accuracy: 0.1046\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6966 - accuracy: 0.4041 - val_loss: 3.0846 - val_accuracy: 0.1014\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6973 - accuracy: 0.4037 - val_loss: 3.0808 - val_accuracy: 0.1061\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6955 - accuracy: 0.4028 - val_loss: 3.1050 - val_accuracy: 0.1039\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6868 - accuracy: 0.4049 - val_loss: 3.0730 - val_accuracy: 0.0976\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6946 - accuracy: 0.4025 - val_loss: 3.0636 - val_accuracy: 0.1055\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6896 - accuracy: 0.4071 - val_loss: 3.0369 - val_accuracy: 0.1049\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6852 - accuracy: 0.4066 - val_loss: 3.0718 - val_accuracy: 0.1027\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6905 - accuracy: 0.4056 - val_loss: 3.0766 - val_accuracy: 0.1054\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6847 - accuracy: 0.4045 - val_loss: 3.0762 - val_accuracy: 0.0981\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6886 - accuracy: 0.4048 - val_loss: 3.1032 - val_accuracy: 0.1023\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6840 - accuracy: 0.4063 - val_loss: 3.1109 - val_accuracy: 0.0989\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6852 - accuracy: 0.4037 - val_loss: 3.0476 - val_accuracy: 0.1072\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6834 - accuracy: 0.4072 - val_loss: 3.1174 - val_accuracy: 0.0983\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6716 - accuracy: 0.4081 - val_loss: 3.0852 - val_accuracy: 0.1023\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6809 - accuracy: 0.4070 - val_loss: 3.1163 - val_accuracy: 0.1019\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6710 - accuracy: 0.4133 - val_loss: 3.1442 - val_accuracy: 0.0992\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6748 - accuracy: 0.4114 - val_loss: 3.0949 - val_accuracy: 0.1071\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6708 - accuracy: 0.4112 - val_loss: 3.0875 - val_accuracy: 0.1128\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6748 - accuracy: 0.4086 - val_loss: 3.1127 - val_accuracy: 0.1009\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6829 - accuracy: 0.4081 - val_loss: 3.0811 - val_accuracy: 0.1082\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6735 - accuracy: 0.4146 - val_loss: 3.0865 - val_accuracy: 0.1022\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6783 - accuracy: 0.4077 - val_loss: 3.0981 - val_accuracy: 0.1014\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6621 - accuracy: 0.4145 - val_loss: 3.1085 - val_accuracy: 0.1079\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6713 - accuracy: 0.4122 - val_loss: 3.0576 - val_accuracy: 0.1077\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6677 - accuracy: 0.4125 - val_loss: 3.1125 - val_accuracy: 0.1054\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6639 - accuracy: 0.4165 - val_loss: 3.1144 - val_accuracy: 0.0971\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6658 - accuracy: 0.4171 - val_loss: 3.1281 - val_accuracy: 0.0997\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6649 - accuracy: 0.4157 - val_loss: 3.1046 - val_accuracy: 0.1127\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6595 - accuracy: 0.4191 - val_loss: 3.1019 - val_accuracy: 0.1073\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6519 - accuracy: 0.4165 - val_loss: 3.0835 - val_accuracy: 0.1092\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6589 - accuracy: 0.4154 - val_loss: 3.1436 - val_accuracy: 0.1028\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6652 - accuracy: 0.4132 - val_loss: 3.1287 - val_accuracy: 0.1083\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6560 - accuracy: 0.4151 - val_loss: 3.0730 - val_accuracy: 0.1099\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6664 - accuracy: 0.4129 - val_loss: 3.1706 - val_accuracy: 0.1022\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6624 - accuracy: 0.4153 - val_loss: 3.0827 - val_accuracy: 0.1081\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6514 - accuracy: 0.4187 - val_loss: 3.1310 - val_accuracy: 0.1020\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6515 - accuracy: 0.4213 - val_loss: 3.1816 - val_accuracy: 0.1018\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6524 - accuracy: 0.4209 - val_loss: 3.1464 - val_accuracy: 0.1000\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6549 - accuracy: 0.4179 - val_loss: 3.1353 - val_accuracy: 0.1068\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6562 - accuracy: 0.4192 - val_loss: 3.1758 - val_accuracy: 0.1018\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6407 - accuracy: 0.4249 - val_loss: 3.1596 - val_accuracy: 0.1074\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6507 - accuracy: 0.4181 - val_loss: 3.1213 - val_accuracy: 0.1156\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6509 - accuracy: 0.4193 - val_loss: 3.1357 - val_accuracy: 0.1068\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6490 - accuracy: 0.4199 - val_loss: 3.1602 - val_accuracy: 0.1025\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6477 - accuracy: 0.4200 - val_loss: 3.1571 - val_accuracy: 0.1019\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6476 - accuracy: 0.4227 - val_loss: 3.1867 - val_accuracy: 0.0996\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6545 - accuracy: 0.4201 - val_loss: 3.1723 - val_accuracy: 0.1019\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6435 - accuracy: 0.4203 - val_loss: 3.1561 - val_accuracy: 0.1027\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6479 - accuracy: 0.4197 - val_loss: 3.1678 - val_accuracy: 0.1033\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6417 - accuracy: 0.4239 - val_loss: 3.1967 - val_accuracy: 0.1009\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6434 - accuracy: 0.4183 - val_loss: 3.1717 - val_accuracy: 0.1012\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6301 - accuracy: 0.4251 - val_loss: 3.1595 - val_accuracy: 0.1101\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6467 - accuracy: 0.4220 - val_loss: 3.1965 - val_accuracy: 0.1021\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6328 - accuracy: 0.4243 - val_loss: 3.1797 - val_accuracy: 0.1033\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6369 - accuracy: 0.4241 - val_loss: 3.2066 - val_accuracy: 0.0966\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6341 - accuracy: 0.4225 - val_loss: 3.1674 - val_accuracy: 0.1047\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6317 - accuracy: 0.4233 - val_loss: 3.1699 - val_accuracy: 0.1021\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6378 - accuracy: 0.4210 - val_loss: 3.1958 - val_accuracy: 0.0995\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6346 - accuracy: 0.4241 - val_loss: 3.1540 - val_accuracy: 0.1052\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6413 - accuracy: 0.4220 - val_loss: 3.1913 - val_accuracy: 0.1042\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6332 - accuracy: 0.4254 - val_loss: 3.1907 - val_accuracy: 0.1024\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6312 - accuracy: 0.4273 - val_loss: 3.1834 - val_accuracy: 0.1077\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6328 - accuracy: 0.4240 - val_loss: 3.1977 - val_accuracy: 0.1081\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6316 - accuracy: 0.4259 - val_loss: 3.1880 - val_accuracy: 0.1088\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6275 - accuracy: 0.4265 - val_loss: 3.1804 - val_accuracy: 0.1058\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6259 - accuracy: 0.4296 - val_loss: 3.2316 - val_accuracy: 0.1017\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6207 - accuracy: 0.4330 - val_loss: 3.2203 - val_accuracy: 0.1003\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6296 - accuracy: 0.4251 - val_loss: 3.1969 - val_accuracy: 0.1049\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6245 - accuracy: 0.4298 - val_loss: 3.2074 - val_accuracy: 0.1055\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6291 - accuracy: 0.4243 - val_loss: 3.2145 - val_accuracy: 0.1019\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6313 - accuracy: 0.4262 - val_loss: 3.2218 - val_accuracy: 0.0981\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6251 - accuracy: 0.4275 - val_loss: 3.1867 - val_accuracy: 0.1071\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6195 - accuracy: 0.4273 - val_loss: 3.2172 - val_accuracy: 0.1013\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6203 - accuracy: 0.4299 - val_loss: 3.1818 - val_accuracy: 0.1034\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6216 - accuracy: 0.4288 - val_loss: 3.2140 - val_accuracy: 0.1057\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6243 - accuracy: 0.4282 - val_loss: 3.2032 - val_accuracy: 0.1055\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6167 - accuracy: 0.4312 - val_loss: 3.2474 - val_accuracy: 0.0962\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6306 - accuracy: 0.4270 - val_loss: 3.2491 - val_accuracy: 0.0971\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6194 - accuracy: 0.4307 - val_loss: 3.2033 - val_accuracy: 0.1056\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6223 - accuracy: 0.4260 - val_loss: 3.1847 - val_accuracy: 0.1166\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6305 - accuracy: 0.4291 - val_loss: 3.2225 - val_accuracy: 0.1067\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6221 - accuracy: 0.4316 - val_loss: 3.1992 - val_accuracy: 0.0991\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6240 - accuracy: 0.4306 - val_loss: 3.1800 - val_accuracy: 0.1050\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6169 - accuracy: 0.4316 - val_loss: 3.1925 - val_accuracy: 0.1113\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6118 - accuracy: 0.4340 - val_loss: 3.2590 - val_accuracy: 0.0979\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6182 - accuracy: 0.4307 - val_loss: 3.2317 - val_accuracy: 0.1037\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6102 - accuracy: 0.4328 - val_loss: 3.2246 - val_accuracy: 0.1065\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6201 - accuracy: 0.4283 - val_loss: 3.1972 - val_accuracy: 0.1049\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6081 - accuracy: 0.4338 - val_loss: 3.2612 - val_accuracy: 0.0995\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6136 - accuracy: 0.4325 - val_loss: 3.2564 - val_accuracy: 0.1010\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6135 - accuracy: 0.4317 - val_loss: 3.1941 - val_accuracy: 0.1121\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6116 - accuracy: 0.4348 - val_loss: 3.2258 - val_accuracy: 0.1040\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6075 - accuracy: 0.4326 - val_loss: 3.2188 - val_accuracy: 0.1037\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6071 - accuracy: 0.4337 - val_loss: 3.1805 - val_accuracy: 0.1104\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6088 - accuracy: 0.4334 - val_loss: 3.2251 - val_accuracy: 0.1067\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6119 - accuracy: 0.4341 - val_loss: 3.2479 - val_accuracy: 0.1022\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6086 - accuracy: 0.4366 - val_loss: 3.2554 - val_accuracy: 0.1052\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6061 - accuracy: 0.4324 - val_loss: 3.2397 - val_accuracy: 0.1096\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6052 - accuracy: 0.4354 - val_loss: 3.2508 - val_accuracy: 0.1004\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6041 - accuracy: 0.4340 - val_loss: 3.2596 - val_accuracy: 0.1040\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6020 - accuracy: 0.4363 - val_loss: 3.2717 - val_accuracy: 0.1011\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6078 - accuracy: 0.4307 - val_loss: 3.2313 - val_accuracy: 0.1039\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6027 - accuracy: 0.4380 - val_loss: 3.2527 - val_accuracy: 0.1069\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5962 - accuracy: 0.4398 - val_loss: 3.2179 - val_accuracy: 0.1082\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6086 - accuracy: 0.4344 - val_loss: 3.2595 - val_accuracy: 0.1069\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6011 - accuracy: 0.4388 - val_loss: 3.2189 - val_accuracy: 0.1143\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6070 - accuracy: 0.4343 - val_loss: 3.2808 - val_accuracy: 0.1054\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6122 - accuracy: 0.4355 - val_loss: 3.2404 - val_accuracy: 0.1125\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6084 - accuracy: 0.4353 - val_loss: 3.2656 - val_accuracy: 0.1063\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6016 - accuracy: 0.4343 - val_loss: 3.2301 - val_accuracy: 0.1115\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5942 - accuracy: 0.4393 - val_loss: 3.2824 - val_accuracy: 0.1068\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5913 - accuracy: 0.4416 - val_loss: 3.2841 - val_accuracy: 0.1000\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6012 - accuracy: 0.4379 - val_loss: 3.2631 - val_accuracy: 0.1036\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5966 - accuracy: 0.4388 - val_loss: 3.3035 - val_accuracy: 0.1067\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.6002 - accuracy: 0.4355 - val_loss: 3.2828 - val_accuracy: 0.1090\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5819 - accuracy: 0.4447 - val_loss: 3.2806 - val_accuracy: 0.1034\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5928 - accuracy: 0.4397 - val_loss: 3.2805 - val_accuracy: 0.0995\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6038 - accuracy: 0.4351 - val_loss: 3.2987 - val_accuracy: 0.1029\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5913 - accuracy: 0.4453 - val_loss: 3.2491 - val_accuracy: 0.1057\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5887 - accuracy: 0.4426 - val_loss: 3.2437 - val_accuracy: 0.1091\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6010 - accuracy: 0.4408 - val_loss: 3.2460 - val_accuracy: 0.1056\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5912 - accuracy: 0.4379 - val_loss: 3.2687 - val_accuracy: 0.1094\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5951 - accuracy: 0.4349 - val_loss: 3.2829 - val_accuracy: 0.1128\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5896 - accuracy: 0.4395 - val_loss: 3.2537 - val_accuracy: 0.0993\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5943 - accuracy: 0.4375 - val_loss: 3.2633 - val_accuracy: 0.1026\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5982 - accuracy: 0.4370 - val_loss: 3.2577 - val_accuracy: 0.1079\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5936 - accuracy: 0.4399 - val_loss: 3.2658 - val_accuracy: 0.1108\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5884 - accuracy: 0.4429 - val_loss: 3.2745 - val_accuracy: 0.1049\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5813 - accuracy: 0.4442 - val_loss: 3.2693 - val_accuracy: 0.1105\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5914 - accuracy: 0.4408 - val_loss: 3.3171 - val_accuracy: 0.1092\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5883 - accuracy: 0.4408 - val_loss: 3.3124 - val_accuracy: 0.1035\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5872 - accuracy: 0.4423 - val_loss: 3.2438 - val_accuracy: 0.1105\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5801 - accuracy: 0.4441 - val_loss: 3.2858 - val_accuracy: 0.1071\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5809 - accuracy: 0.4453 - val_loss: 3.2932 - val_accuracy: 0.1048\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5914 - accuracy: 0.4410 - val_loss: 3.3235 - val_accuracy: 0.1025\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5874 - accuracy: 0.4407 - val_loss: 3.2941 - val_accuracy: 0.1101\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5801 - accuracy: 0.4448 - val_loss: 3.3350 - val_accuracy: 0.1020\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5877 - accuracy: 0.4413 - val_loss: 3.2948 - val_accuracy: 0.1036\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5825 - accuracy: 0.4439 - val_loss: 3.3212 - val_accuracy: 0.1033\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5829 - accuracy: 0.4435 - val_loss: 3.3128 - val_accuracy: 0.1043\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5828 - accuracy: 0.4426 - val_loss: 3.3021 - val_accuracy: 0.1049\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5776 - accuracy: 0.4455 - val_loss: 3.2976 - val_accuracy: 0.1098\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5764 - accuracy: 0.4452 - val_loss: 3.3400 - val_accuracy: 0.1018\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5716 - accuracy: 0.4491 - val_loss: 3.3443 - val_accuracy: 0.1013\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5799 - accuracy: 0.4429 - val_loss: 3.2944 - val_accuracy: 0.1065\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5876 - accuracy: 0.4391 - val_loss: 3.3623 - val_accuracy: 0.1038\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5818 - accuracy: 0.4417 - val_loss: 3.3292 - val_accuracy: 0.1077\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5820 - accuracy: 0.4457 - val_loss: 3.3018 - val_accuracy: 0.1077\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5829 - accuracy: 0.4417 - val_loss: 3.3084 - val_accuracy: 0.1024\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5812 - accuracy: 0.4467 - val_loss: 3.3110 - val_accuracy: 0.1108\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5774 - accuracy: 0.4468 - val_loss: 3.3788 - val_accuracy: 0.1007\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5821 - accuracy: 0.4436 - val_loss: 3.3526 - val_accuracy: 0.0974\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5839 - accuracy: 0.4422 - val_loss: 3.3129 - val_accuracy: 0.1066\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5720 - accuracy: 0.4482 - val_loss: 3.3432 - val_accuracy: 0.1063\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5702 - accuracy: 0.4472 - val_loss: 3.3288 - val_accuracy: 0.1032\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5719 - accuracy: 0.4468 - val_loss: 3.3414 - val_accuracy: 0.1023\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5765 - accuracy: 0.4456 - val_loss: 3.3061 - val_accuracy: 0.1090\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5731 - accuracy: 0.4482 - val_loss: 3.3251 - val_accuracy: 0.1010\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5778 - accuracy: 0.4421 - val_loss: 3.3457 - val_accuracy: 0.1016\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5770 - accuracy: 0.4438 - val_loss: 3.3265 - val_accuracy: 0.1028\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5739 - accuracy: 0.4435 - val_loss: 3.3241 - val_accuracy: 0.1029\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5813 - accuracy: 0.4436 - val_loss: 3.3276 - val_accuracy: 0.1077\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5718 - accuracy: 0.4452 - val_loss: 3.3624 - val_accuracy: 0.1015\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5726 - accuracy: 0.4515 - val_loss: 3.3489 - val_accuracy: 0.1041\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5695 - accuracy: 0.4477 - val_loss: 3.3288 - val_accuracy: 0.1071\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5737 - accuracy: 0.4449 - val_loss: 3.3574 - val_accuracy: 0.1048\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5729 - accuracy: 0.4487 - val_loss: 3.3730 - val_accuracy: 0.1012\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.5700 - accuracy: 0.4465 - val_loss: 3.3152 - val_accuracy: 0.1085\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5750 - accuracy: 0.4436 - val_loss: 3.3593 - val_accuracy: 0.1088\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5813 - accuracy: 0.4417 - val_loss: 3.3394 - val_accuracy: 0.1091\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5719 - accuracy: 0.4479 - val_loss: 3.3078 - val_accuracy: 0.1144\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5750 - accuracy: 0.4455 - val_loss: 3.3332 - val_accuracy: 0.1058\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5715 - accuracy: 0.4461 - val_loss: 3.3321 - val_accuracy: 0.1109\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5653 - accuracy: 0.4504 - val_loss: 3.3423 - val_accuracy: 0.1038\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5710 - accuracy: 0.4467 - val_loss: 3.3523 - val_accuracy: 0.1072\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5748 - accuracy: 0.4452 - val_loss: 3.3099 - val_accuracy: 0.1068\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5636 - accuracy: 0.4511 - val_loss: 3.3252 - val_accuracy: 0.1073\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5623 - accuracy: 0.4485 - val_loss: 3.3658 - val_accuracy: 0.1005\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5618 - accuracy: 0.4495 - val_loss: 3.3754 - val_accuracy: 0.1063\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5646 - accuracy: 0.4510 - val_loss: 3.3378 - val_accuracy: 0.1076\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5604 - accuracy: 0.4516 - val_loss: 3.3796 - val_accuracy: 0.1048\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5640 - accuracy: 0.4511 - val_loss: 3.3339 - val_accuracy: 0.1111\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5573 - accuracy: 0.4531 - val_loss: 3.3718 - val_accuracy: 0.1073\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5515 - accuracy: 0.4535 - val_loss: 3.3726 - val_accuracy: 0.1008\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5600 - accuracy: 0.4514 - val_loss: 3.3851 - val_accuracy: 0.1019\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5609 - accuracy: 0.4538 - val_loss: 3.3096 - val_accuracy: 0.1098\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5718 - accuracy: 0.4471 - val_loss: 3.3599 - val_accuracy: 0.1050\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5632 - accuracy: 0.4504 - val_loss: 3.3368 - val_accuracy: 0.1049\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5593 - accuracy: 0.4500 - val_loss: 3.3717 - val_accuracy: 0.1025\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5587 - accuracy: 0.4526 - val_loss: 3.3852 - val_accuracy: 0.0979\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5572 - accuracy: 0.4499 - val_loss: 3.4114 - val_accuracy: 0.0976\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5575 - accuracy: 0.4536 - val_loss: 3.3965 - val_accuracy: 0.0944\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5582 - accuracy: 0.4498 - val_loss: 3.3397 - val_accuracy: 0.1126\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5473 - accuracy: 0.4543 - val_loss: 3.3824 - val_accuracy: 0.1051\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5566 - accuracy: 0.4489 - val_loss: 3.4086 - val_accuracy: 0.1075\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5580 - accuracy: 0.4510 - val_loss: 3.3960 - val_accuracy: 0.1026\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5531 - accuracy: 0.4545 - val_loss: 3.3902 - val_accuracy: 0.1021\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5658 - accuracy: 0.4498 - val_loss: 3.3715 - val_accuracy: 0.1046\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5622 - accuracy: 0.4473 - val_loss: 3.3573 - val_accuracy: 0.1097\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5624 - accuracy: 0.4484 - val_loss: 3.4132 - val_accuracy: 0.1031\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5612 - accuracy: 0.4504 - val_loss: 3.3994 - val_accuracy: 0.1011\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5555 - accuracy: 0.4515 - val_loss: 3.3851 - val_accuracy: 0.1011\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5569 - accuracy: 0.4538 - val_loss: 3.3795 - val_accuracy: 0.1034\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5529 - accuracy: 0.4545 - val_loss: 3.4290 - val_accuracy: 0.1057\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5534 - accuracy: 0.4529 - val_loss: 3.3652 - val_accuracy: 0.1068\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5548 - accuracy: 0.4523 - val_loss: 3.4069 - val_accuracy: 0.0994\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5545 - accuracy: 0.4526 - val_loss: 3.4076 - val_accuracy: 0.1036\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5506 - accuracy: 0.4534 - val_loss: 3.3825 - val_accuracy: 0.1003\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5589 - accuracy: 0.4520 - val_loss: 3.3882 - val_accuracy: 0.1031\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5541 - accuracy: 0.4533 - val_loss: 3.4038 - val_accuracy: 0.1058\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5446 - accuracy: 0.4579 - val_loss: 3.4171 - val_accuracy: 0.1065\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5547 - accuracy: 0.4523 - val_loss: 3.4174 - val_accuracy: 0.1012\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5536 - accuracy: 0.4541 - val_loss: 3.3992 - val_accuracy: 0.0994\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5518 - accuracy: 0.4566 - val_loss: 3.3910 - val_accuracy: 0.1074\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5445 - accuracy: 0.4578 - val_loss: 3.3539 - val_accuracy: 0.1079\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5532 - accuracy: 0.4565 - val_loss: 3.3925 - val_accuracy: 0.1085\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5496 - accuracy: 0.4552 - val_loss: 3.4130 - val_accuracy: 0.1022\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5439 - accuracy: 0.4560 - val_loss: 3.3847 - val_accuracy: 0.1077\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.5474 - accuracy: 0.4556 - val_loss: 3.4054 - val_accuracy: 0.1065\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5470 - accuracy: 0.4552 - val_loss: 3.4088 - val_accuracy: 0.1058\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5505 - accuracy: 0.4559 - val_loss: 3.3999 - val_accuracy: 0.1063\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5578 - accuracy: 0.4522 - val_loss: 3.4188 - val_accuracy: 0.1003\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5458 - accuracy: 0.4521 - val_loss: 3.3893 - val_accuracy: 0.1034\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5440 - accuracy: 0.4583 - val_loss: 3.4105 - val_accuracy: 0.1095\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5446 - accuracy: 0.4546 - val_loss: 3.4165 - val_accuracy: 0.1030\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5455 - accuracy: 0.4550 - val_loss: 3.4247 - val_accuracy: 0.1018\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5396 - accuracy: 0.4574 - val_loss: 3.4209 - val_accuracy: 0.1071\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5496 - accuracy: 0.4549 - val_loss: 3.4433 - val_accuracy: 0.1043\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5464 - accuracy: 0.4540 - val_loss: 3.4410 - val_accuracy: 0.1062\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5408 - accuracy: 0.4583 - val_loss: 3.4101 - val_accuracy: 0.0985\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5456 - accuracy: 0.4548 - val_loss: 3.4183 - val_accuracy: 0.1029\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5568 - accuracy: 0.4515 - val_loss: 3.4329 - val_accuracy: 0.1014\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5582 - accuracy: 0.4515 - val_loss: 3.3881 - val_accuracy: 0.1092\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5407 - accuracy: 0.4586 - val_loss: 3.4401 - val_accuracy: 0.1048\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5327 - accuracy: 0.4617 - val_loss: 3.3848 - val_accuracy: 0.1069\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5416 - accuracy: 0.4551 - val_loss: 3.4132 - val_accuracy: 0.1033\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5489 - accuracy: 0.4543 - val_loss: 3.4605 - val_accuracy: 0.0989\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5521 - accuracy: 0.4504 - val_loss: 3.4138 - val_accuracy: 0.1086\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5433 - accuracy: 0.4531 - val_loss: 3.4602 - val_accuracy: 0.0950\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5429 - accuracy: 0.4552 - val_loss: 3.4024 - val_accuracy: 0.1054\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5419 - accuracy: 0.4529 - val_loss: 3.4443 - val_accuracy: 0.1000\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5448 - accuracy: 0.4548 - val_loss: 3.4159 - val_accuracy: 0.1053\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5379 - accuracy: 0.4568 - val_loss: 3.4298 - val_accuracy: 0.1069\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5320 - accuracy: 0.4584 - val_loss: 3.4475 - val_accuracy: 0.1005\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5309 - accuracy: 0.4622 - val_loss: 3.4209 - val_accuracy: 0.1020\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5332 - accuracy: 0.4597 - val_loss: 3.4311 - val_accuracy: 0.1038\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5398 - accuracy: 0.4583 - val_loss: 3.4346 - val_accuracy: 0.1058\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5409 - accuracy: 0.4562 - val_loss: 3.4421 - val_accuracy: 0.0993\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5381 - accuracy: 0.4599 - val_loss: 3.4386 - val_accuracy: 0.1046\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5457 - accuracy: 0.4540 - val_loss: 3.4697 - val_accuracy: 0.0983\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5378 - accuracy: 0.4596 - val_loss: 3.4364 - val_accuracy: 0.1037\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5418 - accuracy: 0.4589 - val_loss: 3.4188 - val_accuracy: 0.1049\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5384 - accuracy: 0.4584 - val_loss: 3.4584 - val_accuracy: 0.1027\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5402 - accuracy: 0.4572 - val_loss: 3.4810 - val_accuracy: 0.0974\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5468 - accuracy: 0.4550 - val_loss: 3.4286 - val_accuracy: 0.1070\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5421 - accuracy: 0.4571 - val_loss: 3.4588 - val_accuracy: 0.1038\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5415 - accuracy: 0.4577 - val_loss: 3.4426 - val_accuracy: 0.1059\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5368 - accuracy: 0.4575 - val_loss: 3.4629 - val_accuracy: 0.1013\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5385 - accuracy: 0.4588 - val_loss: 3.4421 - val_accuracy: 0.1024\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5364 - accuracy: 0.4610 - val_loss: 3.4720 - val_accuracy: 0.0999\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5396 - accuracy: 0.4577 - val_loss: 3.4393 - val_accuracy: 0.0983\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5431 - accuracy: 0.4560 - val_loss: 3.4551 - val_accuracy: 0.1027\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5267 - accuracy: 0.4624 - val_loss: 3.4556 - val_accuracy: 0.1061\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5285 - accuracy: 0.4619 - val_loss: 3.4603 - val_accuracy: 0.1078\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5290 - accuracy: 0.4618 - val_loss: 3.4474 - val_accuracy: 0.1016\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5375 - accuracy: 0.4581 - val_loss: 3.4425 - val_accuracy: 0.1007\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5331 - accuracy: 0.4603 - val_loss: 3.4594 - val_accuracy: 0.1007\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5384 - accuracy: 0.4577 - val_loss: 3.4519 - val_accuracy: 0.1026\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 1.5296 - accuracy: 0.4616 - val_loss: 3.4567 - val_accuracy: 0.1003\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5344 - accuracy: 0.4594 - val_loss: 3.4616 - val_accuracy: 0.1028\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5256 - accuracy: 0.4655 - val_loss: 3.4645 - val_accuracy: 0.1007\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5298 - accuracy: 0.4603 - val_loss: 3.4922 - val_accuracy: 0.0983\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5309 - accuracy: 0.4625 - val_loss: 3.4534 - val_accuracy: 0.1042\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5268 - accuracy: 0.4632 - val_loss: 3.4531 - val_accuracy: 0.0989\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5234 - accuracy: 0.4647 - val_loss: 3.4449 - val_accuracy: 0.1117\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5380 - accuracy: 0.4549 - val_loss: 3.4858 - val_accuracy: 0.0924\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5366 - accuracy: 0.4578 - val_loss: 3.4796 - val_accuracy: 0.1028\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5370 - accuracy: 0.4595 - val_loss: 3.4459 - val_accuracy: 0.1054\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5362 - accuracy: 0.4558 - val_loss: 3.4677 - val_accuracy: 0.1023\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5300 - accuracy: 0.4596 - val_loss: 3.4998 - val_accuracy: 0.1015\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5184 - accuracy: 0.4631 - val_loss: 3.4794 - val_accuracy: 0.1035\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5263 - accuracy: 0.4646 - val_loss: 3.4777 - val_accuracy: 0.1100\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5269 - accuracy: 0.4634 - val_loss: 3.4672 - val_accuracy: 0.1034\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5349 - accuracy: 0.4597 - val_loss: 3.4956 - val_accuracy: 0.0981\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5353 - accuracy: 0.4575 - val_loss: 3.4782 - val_accuracy: 0.0986\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5180 - accuracy: 0.4626 - val_loss: 3.4343 - val_accuracy: 0.1021\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5219 - accuracy: 0.4668 - val_loss: 3.4609 - val_accuracy: 0.0996\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5271 - accuracy: 0.4632 - val_loss: 3.4740 - val_accuracy: 0.1050\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5269 - accuracy: 0.4593 - val_loss: 3.4700 - val_accuracy: 0.1018\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5283 - accuracy: 0.4609 - val_loss: 3.4504 - val_accuracy: 0.1022\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5192 - accuracy: 0.4642 - val_loss: 3.4498 - val_accuracy: 0.1052\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5335 - accuracy: 0.4620 - val_loss: 3.4953 - val_accuracy: 0.0979\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5297 - accuracy: 0.4621 - val_loss: 3.4344 - val_accuracy: 0.1084\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5215 - accuracy: 0.4652 - val_loss: 3.4754 - val_accuracy: 0.1022\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5317 - accuracy: 0.4613 - val_loss: 3.4976 - val_accuracy: 0.0998\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5126 - accuracy: 0.4664 - val_loss: 3.4644 - val_accuracy: 0.0994\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5240 - accuracy: 0.4644 - val_loss: 3.5017 - val_accuracy: 0.0985\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5241 - accuracy: 0.4663 - val_loss: 3.4750 - val_accuracy: 0.1073\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5277 - accuracy: 0.4633 - val_loss: 3.5224 - val_accuracy: 0.0957\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5244 - accuracy: 0.4606 - val_loss: 3.4967 - val_accuracy: 0.1065\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5235 - accuracy: 0.4633 - val_loss: 3.4528 - val_accuracy: 0.1076\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5232 - accuracy: 0.4608 - val_loss: 3.4544 - val_accuracy: 0.1032\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5290 - accuracy: 0.4618 - val_loss: 3.5167 - val_accuracy: 0.0996\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5227 - accuracy: 0.4638 - val_loss: 3.4890 - val_accuracy: 0.1014\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5201 - accuracy: 0.4649 - val_loss: 3.5119 - val_accuracy: 0.0983\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5205 - accuracy: 0.4619 - val_loss: 3.4611 - val_accuracy: 0.1023\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5154 - accuracy: 0.4659 - val_loss: 3.4866 - val_accuracy: 0.1051\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5178 - accuracy: 0.4622 - val_loss: 3.4688 - val_accuracy: 0.1039\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5199 - accuracy: 0.4651 - val_loss: 3.4898 - val_accuracy: 0.1056\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5283 - accuracy: 0.4638 - val_loss: 3.4750 - val_accuracy: 0.1019\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5211 - accuracy: 0.4607 - val_loss: 3.4863 - val_accuracy: 0.1026\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5165 - accuracy: 0.4658 - val_loss: 3.4707 - val_accuracy: 0.1066\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5231 - accuracy: 0.4623 - val_loss: 3.4905 - val_accuracy: 0.0984\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5266 - accuracy: 0.4586 - val_loss: 3.4545 - val_accuracy: 0.1040\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5133 - accuracy: 0.4696 - val_loss: 3.5132 - val_accuracy: 0.0977\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5182 - accuracy: 0.4680 - val_loss: 3.5165 - val_accuracy: 0.1054\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5295 - accuracy: 0.4611 - val_loss: 3.5437 - val_accuracy: 0.0950\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5164 - accuracy: 0.4681 - val_loss: 3.5365 - val_accuracy: 0.0972\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5195 - accuracy: 0.4651 - val_loss: 3.5175 - val_accuracy: 0.1015\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5105 - accuracy: 0.4692 - val_loss: 3.5052 - val_accuracy: 0.1042\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5204 - accuracy: 0.4669 - val_loss: 3.5624 - val_accuracy: 0.0975\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5253 - accuracy: 0.4608 - val_loss: 3.4966 - val_accuracy: 0.1021\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5118 - accuracy: 0.4694 - val_loss: 3.4306 - val_accuracy: 0.1094\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5185 - accuracy: 0.4670 - val_loss: 3.4753 - val_accuracy: 0.1058\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5227 - accuracy: 0.4663 - val_loss: 3.5503 - val_accuracy: 0.0984\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5233 - accuracy: 0.4623 - val_loss: 3.4966 - val_accuracy: 0.1006\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5102 - accuracy: 0.4698 - val_loss: 3.5111 - val_accuracy: 0.1034\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5154 - accuracy: 0.4634 - val_loss: 3.5136 - val_accuracy: 0.0994\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5109 - accuracy: 0.4689 - val_loss: 3.4604 - val_accuracy: 0.1048\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5196 - accuracy: 0.4678 - val_loss: 3.5191 - val_accuracy: 0.1000\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5153 - accuracy: 0.4650 - val_loss: 3.5111 - val_accuracy: 0.1003\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5173 - accuracy: 0.4669 - val_loss: 3.5116 - val_accuracy: 0.0972\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5028 - accuracy: 0.4732 - val_loss: 3.5384 - val_accuracy: 0.0961\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5064 - accuracy: 0.4717 - val_loss: 3.5175 - val_accuracy: 0.1011\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5207 - accuracy: 0.4621 - val_loss: 3.4950 - val_accuracy: 0.1063\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5178 - accuracy: 0.4627 - val_loss: 3.5077 - val_accuracy: 0.1060\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5155 - accuracy: 0.4624 - val_loss: 3.4886 - val_accuracy: 0.1033\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5093 - accuracy: 0.4672 - val_loss: 3.4934 - val_accuracy: 0.1004\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5037 - accuracy: 0.4701 - val_loss: 3.5217 - val_accuracy: 0.1023\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5119 - accuracy: 0.4688 - val_loss: 3.5415 - val_accuracy: 0.1006\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5160 - accuracy: 0.4634 - val_loss: 3.5170 - val_accuracy: 0.1097\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5090 - accuracy: 0.4693 - val_loss: 3.5342 - val_accuracy: 0.1003\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5198 - accuracy: 0.4629 - val_loss: 3.5272 - val_accuracy: 0.1005\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5158 - accuracy: 0.4648 - val_loss: 3.4922 - val_accuracy: 0.1030\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5126 - accuracy: 0.4679 - val_loss: 3.5164 - val_accuracy: 0.0989\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5189 - accuracy: 0.4638 - val_loss: 3.5010 - val_accuracy: 0.1019\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5042 - accuracy: 0.4715 - val_loss: 3.5214 - val_accuracy: 0.0994\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5007 - accuracy: 0.4729 - val_loss: 3.4760 - val_accuracy: 0.1101\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5102 - accuracy: 0.4672 - val_loss: 3.5327 - val_accuracy: 0.1003\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5072 - accuracy: 0.4700 - val_loss: 3.4673 - val_accuracy: 0.1039\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5104 - accuracy: 0.4715 - val_loss: 3.5608 - val_accuracy: 0.1013\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5207 - accuracy: 0.4670 - val_loss: 3.5417 - val_accuracy: 0.0974\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5106 - accuracy: 0.4697 - val_loss: 3.5221 - val_accuracy: 0.1010\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5162 - accuracy: 0.4640 - val_loss: 3.5364 - val_accuracy: 0.1031\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5081 - accuracy: 0.4685 - val_loss: 3.4998 - val_accuracy: 0.1073\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5128 - accuracy: 0.4667 - val_loss: 3.5428 - val_accuracy: 0.1006\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5084 - accuracy: 0.4660 - val_loss: 3.5325 - val_accuracy: 0.1030\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5039 - accuracy: 0.4703 - val_loss: 3.5229 - val_accuracy: 0.1071\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5080 - accuracy: 0.4691 - val_loss: 3.5151 - val_accuracy: 0.1057\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5001 - accuracy: 0.4721 - val_loss: 3.4940 - val_accuracy: 0.1043\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5051 - accuracy: 0.4694 - val_loss: 3.5331 - val_accuracy: 0.1015\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4990 - accuracy: 0.4720 - val_loss: 3.5655 - val_accuracy: 0.1043\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5058 - accuracy: 0.4688 - val_loss: 3.5472 - val_accuracy: 0.0999\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5121 - accuracy: 0.4651 - val_loss: 3.5421 - val_accuracy: 0.0996\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5048 - accuracy: 0.4690 - val_loss: 3.5355 - val_accuracy: 0.1029\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5109 - accuracy: 0.4661 - val_loss: 3.5071 - val_accuracy: 0.1033\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5092 - accuracy: 0.4697 - val_loss: 3.5582 - val_accuracy: 0.1027\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5019 - accuracy: 0.4728 - val_loss: 3.5308 - val_accuracy: 0.1018\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5021 - accuracy: 0.4714 - val_loss: 3.5474 - val_accuracy: 0.0987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldcCchKFLQpX"
      },
      "source": [
        "# The codes below this section will be the CNN network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuPe2pl1ZAJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ba479b-c169-4d8c-86a4-89a70c84134c"
      },
      "source": [
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Training matrix shape (60000, 28, 28, 1)\n",
            "Testing matrix shape (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jeYSTHO5ZAJO"
      },
      "source": [
        "# one-hot format classes\n",
        "\n",
        "nb_classes = 10 # number of unique digits\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Y9Q0wQ9BZAJO"
      },
      "source": [
        "def build_model(first_dense=512):\n",
        "  model = Sequential()                                 # Linear stacking of layers\n",
        "  # Convolution Layer 1\n",
        "  model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  convLayer01 = Activation('relu')                     # activation\n",
        "  model.add(convLayer01)\n",
        "\n",
        "  # Convolution Layer 2\n",
        "  model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  model.add(Activation('relu'))                        # activation\n",
        "  convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "  model.add(convLayer02)\n",
        "\n",
        "  # Convolution Layer 3\n",
        "  model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  convLayer03 = Activation('relu')                     # activation\n",
        "  model.add(convLayer03)\n",
        "\n",
        "  # Convolution Layer 4\n",
        "  model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  model.add(Activation('relu'))                        # activation\n",
        "  convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "  model.add(convLayer04)\n",
        "  model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
        "\n",
        "  # Fully Connected Layer 5\n",
        "  model.add(Dense(first_dense))                                # 512 FCN nodes\n",
        "  model.add(BatchNormalization())                      # normalization\n",
        "  model.add(Activation('relu'))                        # activation\n",
        "\n",
        "  # Fully Connected Layer 6\n",
        "  model.add(Dense(10))                                 # final 10 FCN nodes\n",
        "  model.add(Activation('softmax'))                     # softmax activationss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKKoJXKaZAJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf111382-4ddf-4257-ba6e-a04fd395e006"
      },
      "source": [
        "CNN_model = build_model()\n",
        "print(CNN_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 597,738\n",
            "Trainable params: 596,330\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXjW6lZ7ZAJP"
      },
      "source": [
        "CNN_history = CNN_model.fit(x=X_train, y=Y_train, epochs=50, steps_per_epoch=100, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-7ugepG-HGH"
      },
      "source": [
        "#Third Empirical Study: Unlabeled data take the majority, and verify the pretrained steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3AD3Tmk-R7S"
      },
      "source": [
        "\"\"\"\n",
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "#Flatten the X data for PCA features\n",
        "X_train_Flatten = X_train.reshape(60000, 28*28)\n",
        "X_test_Flatten = X_test.reshape(10000, 28*28)\n",
        "\n",
        "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "nb_classes = 10 # number of unique digits\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\"\"\"\n",
        "\n",
        "#Futher more, decompose the train set to unlabel train set and label train set. We will try to tranfer the PCA from unlabel dataset to the label dataset.\n",
        "\n",
        "X_unlabel, X_label, y_unlabel, y_label = train_test_split(X_train, y_train, test_size = 0.2)\n",
        "X_unlabel_Flatten = X_unlabel.reshape(48000, 28*28)\n",
        "X_label_Flatten = X_label.reshape(12000, 28*28)\n",
        "\n",
        "Y_unlabel = np_utils.to_categorical(y_unlabel, nb_classes)\n",
        "Y_label = np_utils.to_categorical(y_label, nb_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb4EyoOr_a51"
      },
      "source": [
        "#Do the PCA here\n",
        "obj_pca1 = PCA(n_components=60)\n",
        "obj_pca1.fit(X_unlabel_Flatten)\n",
        "\n",
        "obj_pca2 = PCA(n_components=60)\n",
        "obj_pca2.fit(X_label_Flatten)\n",
        "\n",
        "pcs_unlabel = obj_pca1.components_.reshape(60, 28, 28)\n",
        "pcs_label = obj_pca2.components_.reshape(60, 28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czi6n_WE2nTL"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (30,12) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(32):\n",
        "    plt.subplot(4,8,i+1)\n",
        "    plt.imshow(pcs_unlabel[i], cmap='gray', interpolation='none')\n",
        "    \n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZYARwBE2oY0"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (30,12) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(32):\n",
        "    plt.subplot(4,8,i+1)\n",
        "    plt.imshow(pcs_label[i], cmap='gray', interpolation='none')\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgBf8dIAmFr",
        "outputId": "1750495e-f74a-4535-e218-4d8fa363018e"
      },
      "source": [
        "new_X_train_unlabel = X_label_Flatten @ obj_pca1.components_.T #Map the unlabel PCs with the labeled dataset\n",
        "new_X_test = X_test_Flatten @ obj_pca1.components_.T\n",
        "print(new_X_train_unlabel.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12000, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LckcR-0LA66m"
      },
      "source": [
        "pretrain_pca = build_model_single_dense(32)\n",
        "pretrain_pca_history = pretrain_pca.fit(x=new_X_train_unlabel, y = Y_label, epochs=50, steps_per_epoch=20, validation_data=(new_X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER7inAvxCKUo"
      },
      "source": [
        "naive_dense = build_model_single_dense(32)\n",
        "naive_dense_history = naive_dense.fit(x=X_label_Flatten, y = Y_label, epochs=50, steps_per_epoch=20, validation_data=(X_test_Flatten, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jE6L4UxFCrQ8",
        "outputId": "85475da2-292c-4c44-9735-2bb7376fe36d"
      },
      "source": [
        "%matplotlib inline\n",
        "plt.plot(pretrain_pca_history.history['accuracy'])\n",
        "plt.plot(pretrain_pca_history.history['val_accuracy'])\n",
        "plt.plot(naive_dense_history.history['accuracy'])\n",
        "plt.plot(naive_dense_history.history['val_accuracy'])\n",
        "plt.title('compare model')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['pretrain_pca_accuracy', 'pretrain_pca_val_accuracy', 'naive_dence_accuracy', 'naive_dense_val_accuracy'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBVWJ5DiNP1A"
      },
      "source": [
        "X_random_train = unlabel_X.reshape(48000, 28, 28, 1)\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "X_CNN_train = label_X.reshape(12000, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il818OLeOIMo"
      },
      "source": [
        "CNN_model = build_model()\n",
        "CNN_random_history = CNN_model.fit(x=X_random_train, y = Y_random, epochs=50, steps_per_epoch=200, batch_size=200, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JyTTsRoT65Y"
      },
      "source": [
        "print(CNN_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKnu4GV8UBGg"
      },
      "source": [
        "for layer in CNN_model.layers[:]:\n",
        "  layer.trainable = False\n",
        "\n",
        "for i in range(-5, 0):\n",
        "  CNN_model.layers[i].trainable= True\n",
        "\n",
        "model_status(CNN_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rifH0oRWNdO"
      },
      "source": [
        "X_label = label_X.reshape(12000, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ybQHJD1V0H6"
      },
      "source": [
        "CNN_finetune_history = CNN_model.fit(x=X_label, y = Y_label, epochs=50, steps_per_epoch=100, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}